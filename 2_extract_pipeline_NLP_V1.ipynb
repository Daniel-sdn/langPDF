{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark> <b> > 2.0 </b> Pipeline de Extracao de dados de documentos - NLP </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2_extract_pipeline_NLP_V0.ipynb</b>    |     Atual notebook com as funçoes para processamento de documentos com soluçao NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules e config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 10:24:11.764424: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-30 10:24:11.836200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-30 10:24:12.512035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-30 10:24:12.916879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 10:24:12.917294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-30 10:24:12.917325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from urllib import response\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "import zipfile\n",
    "from pyunpack import Archive\n",
    "import py7zr\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import PyPDF2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "import locale\n",
    "import time, copy\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import cv2\n",
    "import fitz  # Módulo PyMuPDF\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Token\n",
    "from spacy.language import Language\n",
    "from difflib import SequenceMatcher # verificar\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "\n",
    "import logging\n",
    "from icecream import ic\n",
    "ic.disable()\n",
    "\n",
    "# Modulos da solucao\n",
    "# import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron\n",
    "import modules.nova_extracao_pdf_pesquisavel as novaextra \n",
    "import modules.trata_model as tmod\n",
    "import modules.trata_pdf as tpdf\n",
    "import modules.utils as utl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.organization = \"org-guDH0aNEdRkxo8bOtlGqBstO\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from pandasai import PandasAI\n",
    "from pandasai.llm.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "ner = nlp.remove_pipe('ner')\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.utf8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de documento em uso\n",
    "tipo_doc_work = 'nfs_e'\n",
    "\n",
    "# 1. XXX Path para planilha de processamento de batches\n",
    "conf_export_plan_path = 'processamentos/processamento_batches/df_conf_export_batch.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "# 2. XXX  Tratando nome de carga do df_processamento\n",
    "map_analise_path = \"processamentos/mapeamento_analise\"\n",
    "\n",
    "# 3. XXX  prefixo de nome do arquivo de exportaçao\n",
    "df_root_pipe_file = \"df_root_\"\n",
    "\n",
    "# 4. XXX Tipos de documentos para extracao\n",
    "tipo_documento_path = \"config/tipo_documentos\"\n",
    "\n",
    "# 5. XXX Path para tipo de documento patterns\n",
    "tipo_documento_patterns_path = \"config/tipo_documentos/patterns\"\n",
    "\n",
    "# 6. XXX Nome do caminha para dict Tipo de documento\n",
    "config_tipo_doc_path = \"config/tipo_documentos/tipo_documento.json\"\n",
    "\n",
    "# Paths de trabalho para Raster_PDF\n",
    "raster_process_pdf_path = 'processamentos/temp/pdf'\n",
    "raster_process_txt_path = 'processamentos/temp/txt'\n",
    "\n",
    "\n",
    "# 6. IMPORTANTE - MUDOU - Path para gestao de imagens resized\n",
    "image_resized_path = \"processamentos/temp/images/processadas\"\n",
    "\n",
    "\n",
    "#### Config - E-mail\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/11_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/13_attachments'\n",
    "\n",
    "\n",
    "#### Config - messages\n",
    "# 3. Caminho do arquivo uma mensagem especifica\n",
    "msg_outros_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/12_messages'\n",
    "\n",
    "# 4. Path para arquivos recebidos manualmente\n",
    "arquivos_recebidos_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/14_documentos_recebidos'\n",
    "\n",
    "\n",
    "####Config Processamento Pipeline\n",
    "\n",
    "# 5. Path para documentos para extracao\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento\"\n",
    "\n",
    "\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"processamentos/jsons\"\n",
    "\n",
    "# 7. Path para DFs e CSVs exportados\n",
    "export_path = \"pipeline_extracao_documentos/6_geral_administacao/exports\"\n",
    "\n",
    "# 8. Path para lixeira\n",
    "root_garbage_path = \"pipeline_extracao_documentos/0_lixeira\"\n",
    "\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "cnae_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets/CNAE_X_ITEM_SERVICO_PREFEITURAS.xlsx\"\n",
    "\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "#Modelo atual\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "# definindo localizadcao para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     filename='config/log_ocorrencias.log',\n",
    "#     level=logging.INFO, \n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "#     datefmt='%d/%m/%Y %H:%M:%S'\n",
    "# )\n",
    "\n",
    "# logging.info(\"kernel reiniciado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dados_iniciais(idx, row, row_info, texto_tratado, debug):\n",
    "    \n",
    "    dados_iniciais_nf = {}\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    \n",
    "    dados_iniciais_nf['action_item'] = action_item_row_info\n",
    "    dados_iniciais_nf['informations'] = information_row_info\n",
    "    \n",
    "    print(f'\\nDentro da func define_dados_iniciais:  -action_item_row_info: {action_item_row_info}')\n",
    "   \n",
    "\n",
    "\n",
    "    prefeitura_encontrada = None\n",
    "    de_para_encontrado = None\n",
    "\n",
    "    # 7. ZZZ Dicionário para mapear Prefeitura com sua sigla\n",
    "    de_para_prefeitura = {\n",
    "        \"PREFEITURA DA CIDADE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA DA CIDADE DE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA MUNICIPAL DE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\": \"PM_SPA\",\n",
    "        \"MUNICIPAL DE SAO PEDRO DA ALDEIA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA\\nALDEIA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE MESQUITA\": \"PM_MESQUITA\",\n",
    "        \"PREFEITURA MUNICIPAL DE DE MESQUITA\": \"PM_MESQUITA\",\n",
    "        # ... adicione \n",
    "    }\n",
    "    \n",
    "\n",
    "    templates = {\n",
    "        (\"PM_MAGE\", None): \"MAGE\",\n",
    "        (\"PM_SPA\", None): \"SPA\",\n",
    "        (\"PM_MESQUITA\", None): \"MESQUITA\",\n",
    "        (\"Pague agora com o seu Pix\", None): \"NAO_PROCESSAR\",\n",
    "        # ... adicione outras combinações aqui\n",
    "    }\n",
    "\n",
    "    cnpj_encontrado = None\n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto_tratado:\n",
    "        for pref in de_para_prefeitura.keys():\n",
    "            if pref in linha:\n",
    "                #print(linha)\n",
    "                prefeitura_encontrada = pref\n",
    "                dados_iniciais_nf['prefeitura'] = prefeitura_encontrada\n",
    "                if debug:\n",
    "                    print(f'\\n4.funcao: define_dados_iniciais(texto_tratado) - dentro do loop for de pesquisa prefeitura - prefeitura_encontrada: \\n{prefeitura_encontrada}\\n\\n')\n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if prefeitura_encontrada:\n",
    "        de_para_pm = de_para_prefeitura.get(prefeitura_encontrada)\n",
    "        dados_iniciais_nf['de_para_pm'] = de_para_pm\n",
    "        if debug:\n",
    "            print(f'\\n5.funcao: define_dados_iniciais(texto_tratado) - if prefeitura_encontrada - de_para_pm \\n{de_para_pm}\\n\\n')\n",
    "        if not de_para_pm:\n",
    "            de_para_pm = de_para_prefeitura.get(prefeitura_encontrada, \"NAO_PROCESSAR\")\n",
    "            dados_iniciais_nf['de_para_pm'] = de_para_pm\n",
    "            #print(de_para_pm)\n",
    "    else:\n",
    "        de_para_pm = \"NAO_PROCESSAR\"\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'Nao identificado dados iniciais para o documento'\n",
    "        \n",
    "     \n",
    "        \n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto_tratado:\n",
    "        for de_para, cnpj in templates.keys():\n",
    "            if cnpj and cnpj in linha:\n",
    "                cnpj_encontrado = cnpj\n",
    "                dados_iniciais_nf['cnpj_encontrado'] = cnpj_encontrado\n",
    "                \n",
    "                \n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if de_para_pm:\n",
    "        template_usar = templates.get((de_para_pm, cnpj_encontrado))\n",
    "        logging.info(f'usara template {template_usar} para: {cnpj_encontrado}')\n",
    "        # print(template_usar)\n",
    "        dados_iniciais_nf['model'] = template_usar\n",
    "        if not template_usar:\n",
    "            template_usar = templates.get((de_para_pm, None), \"TEMPLATE_NAO_ENCONTRADO\")\n",
    "            dados_iniciais_nf['model'] = 'NAO_ENC.' \n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'model nao encontrado'\n",
    "    else:\n",
    "        template_usar = \"TEMPLATE_NAO_ENCONTRADO\"\n",
    "        dados_iniciais_nf['model'] = 'NAO_ENC.'\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'model nao encontrado'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #Confirmando se template existe em frames    \n",
    "    try:        \n",
    "        f_type = 'frame'\n",
    "        #template_usar = 'SAO_PEDRO_SUPERMIX'\n",
    "        result = filtrar_df(frames_nf_v4_df, type=f_type, de_para_pm=de_para_pm, model=template_usar)\n",
    "        model = result['model'].values[0]\n",
    "        if model:\n",
    "            template_oficial = model\n",
    "            if model == template_usar:\n",
    "                dados_iniciais_nf['model'] = template_oficial\n",
    "            else:    \n",
    "                template_usar = \"necessario cadastrar\"\n",
    "                dados_iniciais_nf['model'] = \"CADASTRAR\"\n",
    "                \n",
    "            dados_iniciais_nf['model'] = template_usar\n",
    "        else:\n",
    "            template_usar = \"necessario cadastrar\"\n",
    "            dados_iniciais_nf['model'] = \"CADASTRAR\"\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "       error_msg = (f\"Erro busca do template: {e}\") \n",
    "    \n",
    "    dados_iniciais_nf['action_item'] = action_item_row_info \n",
    "    dados_iniciais_nf['informations'] = information_row_info         \n",
    "        \n",
    "    return dados_iniciais_nf  \n",
    "\n",
    "\n",
    "\n",
    "# Unica funcao que devera ser movida para junto das demais funcoes de dicionario\n",
    "def define_rotulo_acao(nome_arquivo):\n",
    "    \n",
    "    for palavra_chave, rotulo in mapeamento_palavras_chave.items():\n",
    "        if palavra_chave.lower() in nome_arquivo.lower():\n",
    "            break\n",
    "    else:\n",
    "        rotulo = 'prov_nota_fiscal' #\"sem_rotulo\"\n",
    "        palavra_chave = 'default'\n",
    "        acao_sugerida = sugestoes_acao.get(rotulo, 'None')\n",
    "        return palavra_chave, rotulo, acao_sugerida\n",
    "        # palavra_chave = 'None' #\"sem_palavra_chave\"\n",
    "        # acao_sugerida = 'None' #\"sem_acao_sugerida\"\n",
    "        \n",
    "        return palavra_chave, rotulo, acao_sugerida\n",
    "        #print(f'nome_arquivo: {nome_arquivo} | rotulo: {rotulo}')\n",
    "    if rotulo != 'None': #\"sem_rotulo\"\n",
    "        acao_sugerida = sugestoes_acao.get(rotulo, 'None') # \"Ação não definida\"\n",
    "        return palavra_chave, rotulo, acao_sugerida\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Dicionário para mapear palavras-chave a rótulos\n",
    "mapeamento_palavras_chave = {\n",
    "    \"relatorio\": \"prov_relatorio\",\n",
    "    \"listagem\": \"prov_listagem\",\n",
    "    \"NF\": \"prov_nota_fiscal\",\n",
    "    \"nf\": \"prov_nota_fiscal\",\n",
    "    \"relatorio\": \"prov_listagem\",\n",
    "    \"sintetico\": \"prov_listagem\",\n",
    "    \"livro\": \"prov_livro_registro\",\n",
    "    \"sintético\": \"prov_listagem\",\n",
    "    \"nota\": \"prov_nota_fiscal\",\n",
    "    \"zip\": \"doc_zip\",\n",
    "    \"rar\": \"doc_rar\",\n",
    "    \"valores\": \"prov_dinheiro\",\n",
    "}\n",
    "\n",
    "# Dicionário mapeando rótulos a ações sugeridas\n",
    "sugestoes_acao = {\n",
    "    \"prov_relatorio\": \"NO_PROCESS\",\n",
    "    \"prov_listagem\": \"NO_PROCESS\",\n",
    "    \"prov_nota_fiscal\": \"PROCESS\",\n",
    "    \"sem_rotulo\": \"MANUAL_REV\",\n",
    "    \"prov_livro_registro\": \"NO_PROCESS\",\n",
    "    \"doc_nao_pdf\": \"verificar\",\n",
    "    \"nao_pdf\": \"NO_PROCESS\",\n",
    "    \"doc_zip\": \"NO_PROCESS\",\n",
    "    \"pdf_mul_paginas\": \"SPLIT\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 2.Testando\n",
    "nome_arquivo = 'batatinha_quando_nasce.pdf' # 'pre-processamento'\n",
    "#palavra_chave, rotulo, acao_sugerida = define_rotulo_acao(nome_arquivo, debug)\n",
    "\n",
    "\n",
    "# carrega o tipo de documento do arquivo        \n",
    "def load_dict_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "# Carrega o dict doc_content em arquivo\n",
    "def load_doc_content_from_file():\n",
    "    file_doc_content_path = os.path.join(map_analise_path, 'doc_content_' + batch_name + \".json\")\n",
    "    with open(file_doc_content_path, 'r') as f:\n",
    "        return json.load(f)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. XXX Buscar proximo Batch caso nao esteja rodando email\n",
    "batch_name = utl.busca_proximo_batch(conf_export_plan_path)\n",
    "\n",
    "# 2. XXX IMPORTANTE, carregar o dict de tipo de documento \n",
    "tipo_documento_dict = load_dict_from_file(config_tipo_doc_path)\n",
    "\n",
    "matcher_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('matcher_pattern_path', 'valor_padrao')\n",
    "entity_ruler_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('entity_ruler_pattern_path', 'valor_padrao')\n",
    "\n",
    "# 3. XXX IMPORTANTE - Modelo a ser utilizado para carregar o dict doc_content\n",
    "doc_content = {}\n",
    "doc_content = load_doc_content_from_file()\n",
    "\n",
    "\n",
    "\n",
    "def import_df_root_pipe():\n",
    "    \n",
    "    file_path_root_pipe = os.path.join(map_analise_path, df_root_pipe_file + batch_name + \".xlsx\") # 4. XXX Definiçao do path para salvar o arquivo\n",
    "    df_root_pipe = pd.read_excel(file_path_root_pipe) # 5. XXX Ler a planilha e cria df_documento_recebido\n",
    "    df_root_pipe.set_index('document_unique_id', inplace=True) # 6. XXX  Ajustar o indice\n",
    "    \n",
    "    return df_root_pipe\n",
    "\n",
    "\n",
    "\n",
    "def importa_model():\n",
    "    \n",
    "    nf_model_path = \"config/modelos/frames_nf_v11.xlsx\"\n",
    "    frames_nf_v4_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "    # Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "    document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "    boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "    sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "    frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "    sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "    field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']\n",
    "\n",
    "    return frames_nf_v4_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_pipe = import_df_root_pipe()\n",
    "frames_nf_v4_df = importa_model()\n",
    "\n",
    "# ic.enable()\n",
    "# ic.disable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>1.0</b> Configuraçoes, funcoes e patterns NLP  </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================================#\n",
    "#                                                                                                   #\n",
    "#                                       FUNCOES LEGADAS                                             #\n",
    "#                                                                                                   #\n",
    "#===================================================================================================#\n",
    "\n",
    "# XXX IMPORTANTE - ESTA E A FUNCAO PARA SER UTILIZADA: POIS CONVERTE PARA CINZA E RESIZE: (4134, 5846)\n",
    "def convert_resize_gray(original_file_name, file_path, image_resized_path):\n",
    "\n",
    "    name_image = utl.conv_filename_no_ext(original_file_name)\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(name_image)}.jpg')\n",
    "    pages = convert_from_path(file_path, 500, poppler_path=poppler_path)\n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((4134, 5846))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "    imagem_gray = resized_pages[0].convert('L')\n",
    "    imagem_gray.save(image_resized_name, 'JPEG')\n",
    "\n",
    "    return  imagem_gray, image_resized_name\n",
    "\n",
    "# XXX Pequenos mas poderosos\n",
    "def extract_text_PIL(image, coordinates):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    image_croped = image.crop((x0, y0, x1, y1))\n",
    "    texto_extraido = pytesseract.image_to_string(image_croped, lang='por', config='--psm 6')\n",
    "    return texto_extraido \n",
    "\n",
    "\n",
    "# 5. XXX Ajusta textoYYY\n",
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited\n",
    "\n",
    "\n",
    "##### Frame functions\n",
    "\n",
    "# funçao importante para buscar coordenadas do frame em funçao do contexto\n",
    "def get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo):\n",
    "    \n",
    "    # row_frame = utl.filtrar_df(frames_nf_v4_df, model=model_map, context_mapping=context_mapping, type=tipo)\n",
    "    \n",
    "    row_frame = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo)]\n",
    "\n",
    "    \n",
    "    # Verificando se row_frame não está vazio\n",
    "    if not row_frame.empty:\n",
    "        # Acessando a primeira linha do DataFrame filtrado e depois acessando as colunas\n",
    "        coodinates = [((row_frame.iloc[0]['x0_p'], row_frame.iloc[0]['y0_p'], row_frame.iloc[0]['x1_p'], row_frame.iloc[0]['y1_p']) if pdf_pesquisavel_map else (row_frame.iloc[0]['x0'], row_frame.iloc[0]['y0'], row_frame.iloc[0]['x1'], row_frame.iloc[0]['y1']))]\n",
    "    else:\n",
    "        # Retornando uma tupla de valores NaN se o DataFrame filtrado estiver vazio\n",
    "        coodinates = [(float('nan'), float('nan'), float('nan'), float('nan'))]\n",
    "    \n",
    "    return coodinates\n",
    "\n",
    "\n",
    "\n",
    "# XXXpara buscar melhor as coordendas dos FRAMES\n",
    "def get_coordinates_filter(pdf_pesquisavel_map, model, tipo, label, section):\n",
    "    \n",
    "    row_frame = frames_nf_v4_df[(frames_nf_v4_df['model'] == model) & (frames_nf_v4_df['label'] == label) & (frames_nf_v4_df['type'] == tipo) & (frames_nf_v4_df['section_json'] == section)]\n",
    "    \n",
    "    # Verificando se row_frame não está vazio\n",
    "    if not row_frame.empty:\n",
    "        # Acessando a primeira linha do DataFrame filtrado e depois acessando as colunas\n",
    "        coodinates = [((row_frame.iloc[0]['x0_p'], row_frame.iloc[0]['y0_p'], row_frame.iloc[0]['x1_p'], row_frame.iloc[0]['y1_p']) if pdf_pesquisavel_map else (row_frame.iloc[0]['x0'], row_frame.iloc[0]['y0'], row_frame.iloc[0]['x1'], row_frame.iloc[0]['y1']))]\n",
    "    else:\n",
    "        # Retornando uma tupla de valores NaN se o DataFrame filtrado estiver vazio\n",
    "        coodinates = [(float('nan'), float('nan'), float('nan'), float('nan'))]\n",
    "    \n",
    "    return coodinates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.A Dados iniciais - PDF PESQUISAVEL\t\n",
    "def pesquisa_prefeitura_pdf_pesquisavel(idx, row, row_info, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 4\n",
    "    x1 = 600\n",
    "    y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\ndentro da funçao: pesquisa_prefeitura_pdf_pesquisavel: doc.:{original_file_name} | diretorio: {map_directory}  text: \\n\\n{text}\\n\\n')\n",
    "    \n",
    "    if text:\n",
    "       page_number = 0\n",
    "       #print(page_number)\n",
    "    else:\n",
    "       page_number = 1\n",
    "       #print(page_number)\n",
    "    \n",
    "    pdf_document.close()\n",
    "   \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0. INFOMACOES INICIAIS - RASTER PDF\n",
    "def processar_dados_iniciais(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):\n",
    "    \n",
    "    # lista_texto_extraido = []\n",
    "\n",
    "    nf_dados_doc = {}\n",
    "    nf_dados_doc['secao'] = section\n",
    "    pdf_pesquisavel = None\n",
    "    extracted_txt = pesquisa_prefeitura_pdf_pesquisavel(idx, row, row_info, map_directory, original_file_name, file_path, debug)\n",
    "    if debug:\n",
    "        print(f'\\n1. funcao: processar_dados_iniciais: doc.:{original_file_name} | diretorio: {map_directory} apos funcao: pesquisa_prefeitura_pdf_pesquisavel: extracted_txt:\\n{extracted_txt}\\n\\n')\n",
    "    \n",
    "    if extracted_txt:\n",
    "        pdf_pesquisavel = True\n",
    "        print(f'extracted_txt: {extracted_txt} - portanto pdf_pesquisavel: {pdf_pesquisavel} ')\n",
    "        \n",
    "    else:\n",
    "        pdf_pesquisavel = False\n",
    "        print(f'extracted_txt: {extracted_txt} - portanto pdf_pesquisavel: {pdf_pesquisavel} ') \n",
    "       \n",
    "       \n",
    "        # WTF\n",
    "        x0 = 220\n",
    "        y0 = 0\n",
    "        x1= 3858\n",
    "        y1 = 1572\n",
    "        \n",
    "        # usando novo processo que gera o arquivo \"on the fly\" imagem_gray (converte PDF para imagem de tamanho grande (4134, 5846) - torna-a cinza e a salva)\n",
    "        imagem_gray, image_resized_name = convert_resize_gray(original_file_name, file_path, image_resized_path)\n",
    "        extracted_txt = extract_text_PIL(imagem_gray, (x0, y0, x1, y1))\n",
    "        #print(f'extracted_txt: {extracted_txt}')\n",
    "        if debug:\n",
    "            print(f'\\n2. funcao: processar_dados_iniciaisdoc.:{original_file_name} | diretorio: {map_directory}  apos : extract_text_PIL: extracted_txt:\\n{extracted_txt}\\n\\n')\n",
    "    \n",
    "    nf_dados_doc['file_name'] = original_file_name    \n",
    "    nf_dados_doc['pdf_pesquisavel'] = pdf_pesquisavel \n",
    "    value = {}   \n",
    "    texto_tratado = texto_extraido(extracted_txt)\n",
    "    value = define_dados_iniciais(idx, row, row_info, texto_tratado, debug)\n",
    "    if debug:\n",
    "        print(f'\\n3. funcao: processar_dados_iniciais doc.:{original_file_name} | diretorio: {map_directory} | apos funcao: define_dados_iniciais() value \\n{value}\\n\\n')\n",
    "    if value:\n",
    "        nf_dados_doc.update(value)\n",
    "   \n",
    "\n",
    "\n",
    "    return nf_dados_doc\n",
    "\n",
    "\n",
    "\n",
    "##### Extractions fucntions\n",
    "\n",
    "\n",
    "# 1.B CABECALHO XXX Funcoes de extracao -cabecalho Raster\n",
    "def processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_conferencia = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    # Busco a imagem np do documento\n",
    "    image_np_row_info = row_info.get('image_np')\n",
    "    \n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "    data_box_valores['processo'] = context_mapping\n",
    "    data_box_valores['conf_cod'] = 0\n",
    "\n",
    "\n",
    "                     \n",
    "    \n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "    #print(f'\\n2. Dentro func: section: {section} mapping_method: {mapping_method} | context_mapping: {context_mapping} | model_map: {model_map} | original_file_name: {original_file_name}\\n')\n",
    "   \n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    #print(f'x0: {x0} | y0: {y0} | x1: {x1} | y1: {y1}')\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    data_box_conferencia[f'box_{context_mapping}'] = cropped_image_np\n",
    "    data_box_conferencia[f'coordinates_{context_mapping}'] = coordinates\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    text_splited = texto_extraido_cabecalho(texto_extraido)\n",
    "    if debug:\n",
    "        print()\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'\\ncoordinates {coordinates} - \\ntexto_extraido:\\n{text_splited}\\n')\n",
    "        \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "    \n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        try:\n",
    "            section = row_frame['section_json']\n",
    "            label = row_frame['label']\n",
    "            reference = row_frame['reference']\n",
    "            string_pesquisa = row_frame['marcador_inicio']  \n",
    "            keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "            texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "            data_box_valores[label] = texto\n",
    "            if debug:\n",
    "               print(f'\\nidx: {index_frame:> 3} | label: {label} |  string_pesquisa:{string_pesquisa} | dentro do try do raster PDF cabecalho - texto: \\n{texto}\\n\\n')\n",
    "        except Exception as e:\n",
    "            msg = (f\"{e}\")\n",
    "            data_box_conferencia[label] = msg\n",
    "    \n",
    "\n",
    "    # Verificações após o loop\n",
    "    for key, value in data_box_valores.items():\n",
    "        if key == 'numero_nota_fiscal' and value is None:\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "        \n",
    "        elif key == 'codigo_verificacao' and value != None:\n",
    "            codigo_verificacao_nf = value\n",
    "            tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "            data_box_valores['conf_cod'] = tam_codigo_verificacao\n",
    "            \n",
    "        \n",
    "        elif key != 'numero_nota_fiscal' and value is None:\n",
    "            logging.error(f\" {batch_name_row_info} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "            \n",
    "      # if value is None:\n",
    "        #     logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "\n",
    "    \n",
    "    return data_box_valores\n",
    "\n",
    "# 1.A CABECALHO - PDF PESQUISAVEL  \n",
    "def extrai_cabecalho_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_pm, model_map, f_0, f_1, original_file_name, file_path, debug):\n",
    "    \n",
    "    nf_data_cabecalho = {}\n",
    "    lista_erros = []\n",
    "    label = \"1_frame_dados_nf\"\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    nf_data_cabecalho['secao'] = section\n",
    "    nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "    nf_data_cabecalho['informations'] = information_row_info\n",
    "    nf_data_cabecalho['processo'] = 'mapeamento regex - PDF pesquisavel'\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\n\\n2. dentro da funçao extrai_cabecalho_PDF: batch_name: {batch_name_row_info}\\n\\n')\n",
    "    \n",
    "    pdf_document = fitz.open(file_path)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]    \n",
    "    tipo = \"frame\"\n",
    "\n",
    "    coordinates = get_coordinates_filter(pdf_pesquisavel_map=pdf_pesquisavel_map, model=model_map, tipo=tipo, label=label, section=section)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    y0 = y0 * f_0\n",
    "    y1 = y1 * f_1\n",
    "    \n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    if debug:\n",
    "        print(f'\\n3. x0: {x0}, y0: {y0}, x1: {x1}, y1: {y1} f_0: {f_0} f_1: {f_1} | text: \\n{text} \\n\\n')\n",
    "\n",
    "    try:\n",
    "        numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "        if numero_nota_match:\n",
    "            numero_nf = numero_nota_match.group(1)\n",
    "            nf_data_cabecalho['numero_nota_fiscal'] = numero_nf\n",
    "            #nf_data_cabecalho['informations'] = 'documento com numero de nota fiscal'\n",
    "            if debug:\n",
    "                print(f'\\nnr_nro_nf: {nr_nro_nf} - doc: {original_file_name}\\n')\n",
    "        else:\n",
    "            msg = (f\"Número da Nota não encontrado\")\n",
    "            nf_data_cabecalho['numero_nota_fiscal'] = None\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            nf_data_cabecalho['informations'] = information_row_info\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "    except Exception as e:\n",
    "        msg = (f\"doc: {original_file_name} | numero NF nao encontrado {e}\")\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = None\n",
    "        information_row_info = 'Número da Nota não encontrado'\n",
    "        nf_data_cabecalho['informations'] = information_row_info\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair codigo Verificacao\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        codigo_verificacao_nf = codigo_verificacao_match.group(1)\n",
    "        nf_data_cabecalho['codigo_verificacao'] =  codigo_verificacao_nf\n",
    "        tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "        nf_data_cabecalho['conf_cod'] = tam_codigo_verificacao\n",
    "        \n",
    "    \n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    return nf_data_cabecalho\n",
    "\n",
    "#===================================================================================================#\n",
    "#                                                                                                   #\n",
    "#                                 PRIMEIRAS FUNCOES NLP                                             #\n",
    "#                                                                                                   #\n",
    "#===================================================================================================#\n",
    "\n",
    "\n",
    "def show_ent_new(text, patterns):\n",
    "    #nlp = spacy.blank(\"pt\")\n",
    "    #ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    ents = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        span = doc.char_span(ent.start_char, ent.end_char, label=ent.label_)\n",
    "        ents.append(span)\n",
    "        \n",
    "    for token in doc:\n",
    "        start = token.idx\n",
    "        end = start + len(token)\n",
    "        tokens.append((token.text, start, end))\n",
    "        \n",
    "    return doc, tokens, ents\n",
    "\n",
    "\n",
    "\n",
    "# chunk.text, chunk.start, chunk.end, chunk.root.head.lemma_, chunk.root.dep_, chunk.doc\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Funcoes para salvar e carregar entity ruler patterns\n",
    "def write_patterns_to_file(patterns, colors, filename):\n",
    "    data = {\"patterns\": patterns, \"colors\": colors}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, ensure_ascii=True, indent=2)\n",
    "        \n",
    "\n",
    "# Funcao para carregar as cores e patterns do Entity ruler        \n",
    "def load_patterns_and_colors(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        patterns = data[\"patterns\"]\n",
    "        colors = data[\"colors\"]\n",
    "    return patterns, colors \n",
    "\n",
    "\n",
    "# Salva do tipo de documento em arquivo\n",
    "def save_tipo_doc_to_file(dic, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dic, f) \n",
    "        \n",
    "\n",
    "\n",
    "# Salva o dict doc_content em arquivo\n",
    "def save_doc_content_to_file(doc_content):\n",
    "    file_doc_content_path = os.path.join(map_analise_path, 'doc_content_' + batch_name + \".json\")\n",
    "    with open(file_doc_content_path, 'w') as f:\n",
    "        json.dump(doc_content, f)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "\n",
    "def run_ocrmypdf(input_file, output_file):\n",
    "    command = [\n",
    "        'ocrmypdf',\n",
    "        '--language', 'por',\n",
    "        '--deskew',\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"OCRmyPDF completed successfully. Output saved to {output_file}.\")\n",
    "    else:\n",
    "        print(f\"OCRmyPDF failed with error: {result.stderr.decode('utf-8')}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# Função para definir o atributo \"is_cnpj\"\n",
    "@Language.component(\"set_cnpj_attribute\")\n",
    "def set_cnpj_attribute(doc):\n",
    "    for i, token in enumerate(doc):\n",
    "        if i < len(doc) - 1:\n",
    "            next_token = doc[i + 1]\n",
    "            if token.shape_ == \"dd.ddd.ddd/\" and next_token.shape_ == \"dddd-dd\":\n",
    "                token._.is_cnpj = True\n",
    "                next_token._.is_cnpj = True\n",
    "            else:\n",
    "                token._.is_cnpj = False\n",
    "    return doc        \n",
    "\n",
    "\n",
    "# Registro do atributo 'is_cnpj'\n",
    "Token.set_extension('is_cnpj', force=True, default=False)\n",
    "\n",
    "\n",
    "# Função para aplicar o matcher\n",
    "@Language.component(\"apply_cnpj_matcher\")\n",
    "def apply_cnpj_matcher(doc):\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        for token in span:\n",
    "            token._.is_cnpj = True\n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "# Funcao que ajusta muito bem formataçao de numeros - moeda e %\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\n",
    "\n",
    "\n",
    "\n",
    "# 0.B XXX Funçao de criacao do PDF Pesquisavel\n",
    "def run_ocrmypdf(input_file, output_file):\n",
    "    command = [\n",
    "        'ocrmypdf',\n",
    "        '--language', 'por',\n",
    "        '--deskew',\n",
    "        '--force-ocr',\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"OCRmyPDF completed successfully. Output saved to {output_file}.\")\n",
    "    else:\n",
    "        print(f\"OCRmyPDF failed with error: {result.stderr.decode('utf-8')}\")\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "        \n",
    "        \n",
    "# 1.A XXX Extracao de texto de todo o documento - PDF PESQUISAVEL\t\n",
    "def extracao_texto_PDF_P(i, document_unique_id, nome_arquivo, file_path, debug):    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text_P = page.get_text(\"text\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    texto_PDF_P = re.sub('\\s+', ' ', text_P).strip()  \n",
    "    if debug:\n",
    "        print(f'\\nFUNC analise_texto_PDF: doc.:{nome_arquivo}   texto_PDF_P: \\n\\n{texto_PDF}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1.B XXX Extracao de texto de todo o documento - RASTER PDF\n",
    "def extracao_texto_Raster_P(i, document_unique_id, nome_arquivo, file_path, debug):    \n",
    "    \n",
    "    output_file = None\n",
    "    txt_document_file = None\n",
    "    \n",
    "    input_file = file_path\n",
    "    \n",
    "    #output_file = \"/home/dani-boy/extractNF/processamentos/temp/documento.pdf\"\n",
    "    output_file = os.path.join(raster_process_pdf_path, document_unique_id + '.pdf')\n",
    "\n",
    "    # 1. XXX Executar o comando OCRmyPDF\n",
    "    run_ocrmypdf(input_file, output_file)\n",
    "\n",
    "    txt_document_file = os.path.join(raster_process_txt_path, document_unique_id + '.txt')\n",
    "\n",
    "    txt_dir = os.path.dirname(txt_document_file)\n",
    "    if not os.path.exists(txt_dir):\n",
    "        os.makedirs(txt_dir)\n",
    "\n",
    "    # Execute o comando\n",
    "    subprocess.run([\"pdftotext\", output_file, txt_document_file])\n",
    "\n",
    "    # 3. XXX Ler o arquivo TXT\n",
    "    with open(txt_document_file, 'r', encoding='utf-8') as arquivo:\n",
    "        texto_OCR_R = arquivo.read()\n",
    "    texto_Raster_P = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "    \n",
    "    os.remove(output_file)\n",
    "    os.remove(txt_document_file)\n",
    "    \n",
    "    return texto_Raster_P  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. XXX Analise de silimaridade doc1 x doc2\n",
    "def analisa_similiaridade_doc(doc1, doc2):\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "\n",
    "    # Calculando Similaridade de Cosseno\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "\n",
    "    print(f\"Score de Similaridade: {similarity_scores[0][0]}\")\n",
    "    \n",
    "    return similarity_scores[0][0]    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.A Extracao de texto de todo o documento - PDF PESQUISAVEL\t\n",
    "def extrai_texto_PDF_P(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text_P = page.get_text(\"text\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    texto_PDF_P = text_P.replace('\\n', ' ') \n",
    "    if debug:\n",
    "        print(f'\\nFUNC extrai_texto_PDF_P: doc.:{original_file_name} | diretorio: {map_directory}  texto_PDF_P: \\n\\n{texto_PDF_P}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processar_cabecalho_PDF_P(idx, row, row_info, section, matches, doc, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio']  \n",
    "        \n",
    "        raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "        \n",
    "        most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))\n",
    "        ##print(f'\\nmost_similar_reference: {most_similar_reference}\\n')\n",
    "        final_value = raw_value.split(\":\", 1)[-1].strip()\n",
    "        data_box_valores[label] = final_value\n",
    "\n",
    "    return data_box_valores \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extrac_cabecalho_R_PDF(idx, row, row_info, doc_content, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug):   \n",
    "     \n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "\n",
    "    # Busco a imagem np do documento\n",
    "    # image_np_row_info = row_info.get('image_np')\n",
    "    image_np_row_info = doc_content.get(idx, {}).get('image_np', 'valor_padrao')\n",
    "\n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "\n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    texto_cabechalho_PDF_Raster = re.sub('\\s+', ' ', texto_extraido).strip() \n",
    "\n",
    "    if debug:\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'texto_cabechalho_PDF_Raster: {texto_cabechalho_PDF_Raster}\\n')  \n",
    "    \n",
    "    return texto_cabechalho_PDF_Raster \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ajusta_texto_Raster_P(idx, row, document_unique_id, original_text, texto_cabechalho_PDF_Raster):\n",
    "\n",
    "    # Passa pelo mapeamento de doc ents para ajustar o texto\n",
    "    doc, tokens, ents = show_ent_new(original_text, patterns=patterns)\n",
    "\n",
    "    nome_prefeitura_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "    nome_prefeitura_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "    secretaria_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "    secretaria_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "    tipo_documento_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "    tipo_documento_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "    prestador_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '2. PRESTADOR DE SERVIÇO'][0]\n",
    "\n",
    "    bloco_prefeitura = original_text[nome_prefeitura_start_char:nome_prefeitura_end_char]\n",
    "    bloco_secretaria = original_text[secretaria_start_char:secretaria_end_char]\n",
    "    bloco_tipo_documento = original_text[tipo_documento_start_char:tipo_documento_end_char]\n",
    "    bloco_inicio_prestador = original_text[prestador_start_char:]\n",
    "\n",
    "    recomposed_text = bloco_prefeitura + ' | ' + bloco_secretaria + ' | ' + bloco_tipo_documento  + ' | ' + texto_cabechalho_PDF_Raster + ' | ' + bloco_inicio_prestador\n",
    "    \n",
    "    return recomposed_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mapeia_cabecalho(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "\n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "    # 9. iter sobre o filtro\n",
    "    i = 1\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio'] \n",
    "        # if debug:\n",
    "        #print(f'\\n1. label: {label} | reference: {reference} | string_pesquisa{string_pesquisa}\\n') \n",
    "        \n",
    "        raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "        #print(f'\\n2. reference: {reference} | raw_value: {raw_value}\\n')\n",
    "        \n",
    "        most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))\n",
    "        #print(f'\\n3. most_similar_reference: {most_similar_reference} \\n')\n",
    "        \n",
    "        if debug:\n",
    "            print(f'\\nmost_similar_reference: {most_similar_reference}\\n')\n",
    "        final_value = raw_value.split(\":\", 1)[-1].strip()\n",
    "        data_box_valores[label] = final_value\n",
    "        #print(f'i: {i} | file_name: {original_file_name}  | label: {label} | reference: {reference} | raw_value: {raw_value} | most_similar_reference: {most_similar_reference}  \\n\\n')\n",
    "        i += 1\n",
    "    \n",
    "    return data_box_valores\n",
    "\n",
    "\n",
    "\n",
    "def mapeia_prestador(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    \n",
    "    texto = doc_content.get(idx, {}).get('content', 'valor_padrao')\n",
    "\n",
    "    # 2. PRESTADOR DE SERVIÇO\n",
    "    prestador_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '2. PRESTADOR DE SERVIÇO'][0]\n",
    "    tomador_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '3. TOMADOR DE SERVIÇO'][0]\n",
    "    text = texto[prestador_end_char:tomador_start_char]\n",
    "\n",
    "    # 1. CNPJ com e sem mascara- Prestador\n",
    "    match = re.search(r'CPF/CNPJ:\\s+(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "    if match:\n",
    "        p_cpf_cnpj_com_mascara = match.group(1).strip()\n",
    "        data_box_valores['p_cpf_cnpj_com_mascara'] = p_cpf_cnpj_com_mascara\n",
    "        #print(f\"p_cpf_cnpj_com_mascara: {p_cpf_cnpj_com_mascara}\")\n",
    "        p_cpf_cnpj_sem_mascara = re.sub(r'\\D', '', match.group(1))\n",
    "        data_box_valores['p_cpf_cnpj_sem_mascara'] = p_cpf_cnpj_sem_mascara\n",
    "        #print(f\"p_cpf_cnpj_sem_mascara: {p_cpf_cnpj_sem_mascara}\")\n",
    "        \n",
    "    # 2. Telefone Prestador\n",
    "    match = re.search(r\"Telefone:(.*?)Inscrição\", text)\n",
    "    if match:\n",
    "        p_telefone = match.group(1).strip()\n",
    "        data_box_valores['p_telefone'] = p_telefone\n",
    "        #print(f\"p_telefone: {p_telefone}\")\n",
    "        \n",
    "    # doc = nlp(p_telefone)  \n",
    "\n",
    "    # 3. Inscrição Municipal - Prestador\n",
    "    match = re.search(r\"Inscrição Municipal:(.*?)Telefone:\", text)\n",
    "    if match:\n",
    "        p_inscricao_municipal = match.group(1).strip()\n",
    "        data_box_valores['p_inscricao_municipal'] = p_inscricao_municipal\n",
    "        #print(f\"p_inscricao_municipal: {p_inscricao_municipal}\")\n",
    "        \n",
    "    # doc = nlp(p_inscricao_municipal)    \n",
    "\n",
    "\n",
    "    # 4. Para o campo Inscrição Estadual PRESTADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"Inscrição Estadual:(.*?)Nome/Razão Social:\", text)\n",
    "    if match:\n",
    "        p_inscricao_estadual = match.group(1).strip()\n",
    "        data_box_valores['p_inscricao_estadual'] = p_inscricao_estadual \n",
    "    else:\n",
    "        p_inscricao_estadual = None\n",
    "        data_box_valores['p_inscricao_estadual'] = p_inscricao_estadual \n",
    "        \n",
    "    #print(f\"p_inscricao_estadual: {p_inscricao_estadual}\")   \n",
    "\n",
    "    # 5. Razao Social Prestador\n",
    "    match = re.search(r\"Nome/Razão Social:(.*?)Nome de Fantasia:\", text)\n",
    "    if match:\n",
    "        razao_social_prestador = match.group(1).strip()\n",
    "        data_box_valores['razao_social_prestador'] = razao_social_prestador\n",
    "        #print(f\"razao_social: {razao_social_prestador}\")\n",
    "        \n",
    "\n",
    "    # 6. Nome de Fantasia - Prestador\n",
    "    match = re.search(r\"Nome de Fantasia:(.*?)Endereço:\", text)\n",
    "    if match:\n",
    "        p_nome_fantasia = match.group(1).strip()\n",
    "        data_box_valores['p_nome_fantasia'] = p_nome_fantasia\n",
    "        #print(f\"p_nome_fantasia: {p_nome_fantasia}\")\n",
    "        \n",
    "\n",
    "    # 7. Endereço Prestador\n",
    "    match = re.search(r\"Endereço:(.*?)E-mail:\", text)\n",
    "    if match:\n",
    "        endereco_prestador = match.group(1).strip()\n",
    "        data_box_valores['endereco_prestador'] = endereco_prestador \n",
    "        #print(f\"endereco_prestador: {endereco_prestador}\")\n",
    "        \n",
    "\n",
    "    # 8. email: Prestador  - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if match:\n",
    "        p_email = match.group(1).strip()\n",
    "        data_box_valores['p_email'] = p_email\n",
    "    else:\n",
    "        p_email = None\n",
    "        data_box_valores['p_email'] = p_email\n",
    "        \n",
    "\n",
    "    return data_box_valores \n",
    "\n",
    "\n",
    "\n",
    "def mapeia_tomador(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    \n",
    "    texto = doc_content.get(idx, {}).get('content', 'valor_padrao')\n",
    "    \n",
    "    # 3. TOMADOR DE SERVIÇO\n",
    "    tomador_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '3. TOMADOR DE SERVIÇO'][0]\n",
    "    servicos_star_char = [ent.start_char for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "    text = texto[tomador_end_char:servicos_star_char]\n",
    "\n",
    "    # 1. CNPJ Tomador\n",
    "    match = re.search(r'CPF/CNPJ:\\s+(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "    if match:\n",
    "        t_cpf_cnpj_com_mascara = match.group(1).strip()\n",
    "        data_box_valores['t_cpf_cnpj_com_mascara'] = t_cpf_cnpj_com_mascara\n",
    "        #print(f\"t_cpf_cnpj_com_mascara: {t_cpf_cnpj_com_mascara}\")\n",
    "        t_cpf_cnpj_sem_mascara = re.sub(r'\\D', '', match.group(1))\n",
    "        data_box_valores['t_cpf_cnpj_sem_mascara'] = t_cpf_cnpj_sem_mascara\n",
    "        #print(f\"t_cpf_cnpj_sem_mascara: {t_cpf_cnpj_sem_mascara}\")\n",
    "    \n",
    "    # 2. Inscrição Municipal TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"INSC:MUNICIPAL:(.*?)RG:\", text)\n",
    "    if match:\n",
    "        t_inscricao_municipal = match.group(1).strip()\n",
    "        data_box_valores['t_inscricao_municipal'] = t_inscricao_municipal\n",
    "    else:\n",
    "        t_inscricao_municipal = None\n",
    "        data_box_valores['t_inscricao_municipal'] = t_inscricao_municipal\n",
    "\n",
    "\n",
    "    #2.1 Inscrição Municipal TOMADOR - variacao de texto\n",
    "    match = re.search(r\"Inscrição Municipal:(.*?)RG:\", text)\n",
    "    if match:\n",
    "        t_inscricao_municipal = match.group(1).strip()\n",
    "        data_box_valores['t_inscricao_municipal'] = t_inscricao_municipal\n",
    "    else:\n",
    "        t_inscricao_municipal = None\n",
    "        data_box_valores['t_inscricao_municipal'] = t_inscricao_municipal\n",
    "\n",
    "\n",
    "    # 3.  Telefone TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"Telefone:(.*?)Inscrição Estadual:\", text)\n",
    "    if match:\n",
    "        t_telefone = match.group(1).strip()\n",
    "        data_box_valores['t_telefone'] = t_telefone\n",
    "    else:\n",
    "        t_telefone = None\n",
    "        data_box_valores['t_telefone'] = t_telefone\n",
    "        \n",
    "    # 4. RG TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"RG:(.*?)Telefone:\", text)\n",
    "    if match:\n",
    "        t_RG = match.group(1).strip()\n",
    "        data_box_valores['t_RG'] = t_RG\n",
    "    else:\n",
    "        t_RG = None\n",
    "        data_box_valores['t_RG'] = t_RG\n",
    "\n",
    "    # 5. Inscrição Estadual TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"Inscrição Estadual:(.*?)Nome/Razão Social:\", text)\n",
    "    if match:\n",
    "        t_inscricao_estadual = match.group(1).strip()\n",
    "        data_box_valores['t_inscricao_estadual'] = t_inscricao_estadual\n",
    "    else:\n",
    "        t_inscricao_estadual = None\n",
    "        data_box_valores['t_inscricao_estadual'] = t_inscricao_estadual\n",
    "\n",
    "    # 6. Nome/Razão Social TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"Nome/Razão Social:(.*?)Endereço:\", text)\n",
    "    if match:\n",
    "        t_nome_razao_social = match.group(1).strip()\n",
    "        data_box_valores['t_nome_razao_social'] = t_nome_razao_social\n",
    "    else:\n",
    "        t_nome_razao_social = None\n",
    "        data_box_valores['t_nome_razao_social'] = t_nome_razao_social\n",
    "    \n",
    "    # 7. Endereço: TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r\"Endereço:(.*?)E-mail:\", text)\n",
    "    if match:\n",
    "        t_endereco = match.group(1).strip()\n",
    "        data_box_valores['t_endereco'] = t_endereco\n",
    "    else:\n",
    "        t_endereco = None\n",
    "        data_box_valores['t_endereco'] = t_endereco\n",
    "        \n",
    "    # 8. email: TOMADOR - Neste caso ele acho a correspondencia mas nao extraiu o valor pois nao ha valor\n",
    "    match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if match:\n",
    "        t_email = match.group(1).strip()\n",
    "        data_box_valores['t_email'] = t_email\n",
    "    else:\n",
    "        t_email = None\n",
    "        data_box_valores['t_email'] = t_email\n",
    "        \n",
    "\n",
    "    return data_box_valores\n",
    "\n",
    "\n",
    "\n",
    "def mapeia_campos_valores(idx, row, row_info, doc_content, doc, matches, section, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    # for match_id, start, end in matches:\n",
    "    #     string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    #     span = doc[start:end]  # Obter o trecho correspondente\n",
    "    #     #print(f\"{string_id}: {span.text}\")\n",
    "        \n",
    "    data_box_valores = {}\n",
    "    context_mapping = 'context_matcher'\n",
    "    tipo_4_filter = \"field_box\"\n",
    "    #text = doc_content.get(idx, {}).get('content', 'valor_padrao')\n",
    "    #print(texto)\n",
    "\n",
    "\n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "    # 9. iter sobre o filtro\n",
    "    i = 1\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio'] \n",
    "        # if debug:\n",
    "        #print(f'\\n1. label: {label} | reference: {reference}\\n') \n",
    "        \n",
    "        raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "        #print(f'\\n2. reference: {reference} | raw_value: {raw_value}\\n')\n",
    "        try:\n",
    "            most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))\n",
    "            \n",
    "            final_value = raw_value.split(\":\", 1)[-1].strip()\n",
    "            final_value = format_number2(final_value)\n",
    "            data_box_valores[label] = final_value\n",
    "            #print(f'i: {i} | file_name: {original_file_name}  | label: {label} | reference: {reference} | raw_value: {raw_value} | most_similar_reference: {most_similar_reference}  final_value: {final_value}\\n')\n",
    "        except Exception as e:\n",
    "            #print(f'Erro: reference: {reference} raw_value: {raw_value} | {e}')\n",
    "            most_similar_reference = None    \n",
    "        #print(f'\\n3. most_similar_reference: {most_similar_reference} \\n')\n",
    "        \n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    return data_box_valores\n",
    "\n",
    "\n",
    "def mapeia_cnae_item(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    \n",
    "    texto = doc_content.get(idx, {}).get('content', 'valor_padrao')\n",
    "\n",
    "    # 6. CNAE e Item da Lista de Serviços\n",
    "    valor_cnae_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '6. CNAE e Item da Lista de Serviços'][0]\n",
    "    valores_impostos_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '7. VALORES E IMPOSTOS'][0]\n",
    "    text = texto[valor_cnae_start_char:valores_impostos_start_char]\n",
    "\n",
    "    match = re.search(r\"CNAE - (.*?)Item da Lista de Serviços\", text)\n",
    "    if match:\n",
    "        cnae_value = match.group(1).strip()\n",
    "        data_box_valores['cnae'] = cnae_value\n",
    "        #print(f\"cnae_value:{cnae_value}\")\n",
    "        #data_box_valores['t_telefone'] = t_telefone\n",
    "    else:\n",
    "        cnae_value = None\n",
    "        data_box_valores['cnae'] = cnae_value\n",
    "        #print(f\"cnae_value: {cnae_value}\")\n",
    "        #data_box_valores['t_telefone'] = t_telefone\n",
    "        \n",
    "    match = re.search(r'Item da Lista de Serviços -\\s+(.+)', text)\n",
    "    if match:\n",
    "        item_value = match.group(1).strip()\n",
    "        data_box_valores['item_lista_servicos'] = item_value\n",
    "        #print(f\"item_value:{item_value}\")\n",
    "        #data_box_valores['t_telefone'] = t_telefone\n",
    "    else:\n",
    "        item_value = None\n",
    "        data_box_valores['item_lista_servicos'] = item_value\n",
    "        #print(f\"item_value: {item_value}\")\n",
    "        #data_box_valores['t_telefone'] = t_telefone  \n",
    "        \n",
    "    return data_box_valores\n",
    "\n",
    "\n",
    "\n",
    "def mapeia_informacoes_criticas(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    \n",
    "    texto = doc_content.get(idx, {}).get('content', 'valor_padrao')\n",
    "    \n",
    "    # 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "    outras_informacoes_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '9. OUTRAS INFORMAÇOES / CRITICAS'][0]\n",
    "    observacoes_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '10. OBSERVACOES'][0]\n",
    "    text = texto[outras_informacoes_end_char:observacoes_start_char]\n",
    "\n",
    "\n",
    "    match = re.search(r\" EXIGIBILIDADE ISS(.*?) REGIME TRIBUTAÇÃO\", text)\n",
    "    if match:\n",
    "        exigibilidade_iss_value = match.group(1).strip()\n",
    "        data_box_valores['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "\n",
    "    else:\n",
    "        exigibilidade_iss_value = None\n",
    "        data_box_valores['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    match = re.search(r\"REGIME TRIBUTAÇÃO(.*?) SIMPLES NACIONAL\", text)\n",
    "    if match:\n",
    "        regime_tributacao_value = match.group(1).strip()\n",
    "        data_box_valores['regime_tributacao'] = regime_tributacao_value\n",
    "\n",
    "    else:\n",
    "        regime_tributacao_value = None\n",
    "        data_box_valores['regime_tributacao'] = regime_tributacao_value\n",
    "\n",
    "        \n",
    "    match = re.search(r\"SIMPLES NACIONAL(.*?) ISSQN RETIDO\", text)\n",
    "    if match:\n",
    "        simples_nacional_value = match.group(1).strip()\n",
    "        data_box_valores['simples_nacional'] = simples_nacional_value\n",
    "\n",
    "    else:\n",
    "        simples_nacional_value = None\n",
    "        data_box_valores['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "    match = re.search(r\"ISSQN RETIDO(.*?) LOCAL. PRESTAÇÃO SERVIÇO\", text)\n",
    "    if match:\n",
    "        local_prestacao_servico_value = match.group(1).strip()\n",
    "        data_box_valores['issqn_retido'] = local_prestacao_servico_value \n",
    "\n",
    "    else:\n",
    "        local_prestacao_servico_value = None\n",
    "        data_box_valores['issqn_retido'] = local_prestacao_servico_value   \n",
    "        \n",
    "    match = re.search(r\"LOCAL. PRESTAÇÃO SERVIÇO(.*?) LOCAL INCIDÊNCIA\", text)\n",
    "    if match:\n",
    "        local_prestacao_servico_value = match.group(1).strip()\n",
    "        data_box_valores['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "\n",
    "    else:\n",
    "        local_prestacao_servico_value = None\n",
    "        data_box_valores['local_prestacao_servico'] = local_prestacao_servico_value  \n",
    "        \n",
    "    match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if match:\n",
    "        local_incidencia_value = match.group(1).strip()\n",
    "        data_box_valores['local_incidencia'] = local_incidencia_value\n",
    "    else:\n",
    "        local_incidencia_value = None\n",
    "        data_box_valores['local_incidencia'] = local_incidencia_value   \n",
    "        \n",
    "\n",
    "    return data_box_valores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def analisar_model_np(file_name, debug=False):\n",
    "    \n",
    "#     doc_analise = utl.filtrar_df(df_result_pipe, original_file_name=file_name) \n",
    "#     pdf_pesquisavel_map = doc_analise['pdf_pesquisavel'].values[0]\n",
    "#     model = doc_analise['model'].values[0]\n",
    "#     original_file_name = doc_analise['original_file_name'].values[0]\n",
    "#     de_para_pm = doc_analise['de_para_pm'].values[0]\n",
    "\n",
    "\n",
    "#     original_file_name = doc_analise['original_file_name'].values[0] \n",
    "#     file_path = doc_analise['file_path'].values[0] \n",
    "#     imagem_gray, image_resized_name = convert_resize_gray(original_file_name, file_path, image_resized_path) \n",
    "\n",
    "        \n",
    "#     image = Image.open(image_resized_name).convert(\"RGB\")\n",
    "#     # Converta a imagem para um array NumPy\n",
    "#     image_np = np.array(image)\n",
    "#     os.remove(image_resized_name)\n",
    "    \n",
    "#     draw_boxes(image_np, frames_nf_v4_df, model, draw_types=dw_types)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "color_mapping = {\n",
    "    \"red\": (1, 0, 0),\n",
    "    \"purple\": (0.5, 0, 0.5),\n",
    "    \"orange\": (1, 0.647, 0),\n",
    "    \"green\": (0, 0.5, 0.196),\n",
    "    \"blue\": (0, 0, 1),\n",
    "    \"yellow\": (1, 1, 0),\n",
    "}\n",
    "\n",
    "\n",
    "def draw_boxes(image_np, df, modelo, draw_types=None):\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Filtrar baseado no modelo e nos tipos de \"boxes\" a serem desenhados\n",
    "    filtered_df = df[df['model'] == modelo]\n",
    "    if draw_types:\n",
    "        filtered_df = filtered_df[filtered_df['type'].isin(draw_types)]\n",
    "    \n",
    "    for index, row in filtered_df.iterrows():\n",
    "        x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        \n",
    "        color = color_mapping.get(row['color'], 'black')\n",
    "        \n",
    "        # Adicionando o retângulo\n",
    "        plt.gca().add_patch(Rectangle((x0, y0), x1-x0, y1-y0, linewidth=1, edgecolor=color, facecolor='none'))\n",
    "        \n",
    "        # Adicionando o rótulo, se existir\n",
    "        label = str(row['label']) if pd.notnull(row['label']) else None\n",
    "        if label:\n",
    "            plt.text(x0 + 10, y0 - 15, label, color=color, fontsize=10)\n",
    "            plt.text(x0 + 20, y0 + 55,(x0, y0, x1, y1), color='black', fontsize=7)\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> <b>1.1</b> Dicts tipo de documento e frames_nf_v4_df  e patterns </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity ruler patterns\n",
    "colors = {\n",
    "            \"secretaria\": \"linear-gradient(90deg, #2ADB5E, #1FA346)\", # Verde Degrade\n",
    "            \"tipo_documento\": \"linear-gradient(90deg, #09D6FF, #08A0D1)\", #Azul medio degrade\n",
    "            \"nome_prefeitura\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", # Roxo claro para lilaz - degrade bem bacana\n",
    "            \"nome_section\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\", #  lilaz - Degrade\n",
    "            \"nome_section\": \"#FFEA7F\", # Laranja claro\n",
    "            \"INSC_MUNICIPAL\": \"#CCA10C\", # Terracota\n",
    "            \"CPF_CNPJ\": \"#CCA10C\", # Terracota\n",
    "            \"campos\": \"#AB9BFC\", # Roxo claro \n",
    "            \"SAFRA\": \"#7AECEC\", # Azul bem claro\n",
    "            \"encerrador\": \"#EE8AF8\" # Rosa medio\n",
    "        }          \n",
    "\n",
    "patternsPrefeitura = [\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mesquita\"}], \"id\": \"PM_MESQUITA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mage\"}], \"id\": \"PM_MAGE\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSection = [     \n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"número\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}, {\"ORTH\": \":\"}], \"id\": \"1. CABECALHO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"discriminação\"}, {\"LOWER\": \"dos\"}, {\"LOWER\": \"serviços\"}], \"id\": \"4. DESCRIMINACAO DOS SERVIÇOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"total\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"},{\"ORTH\": \":\"}], \"id\": \"5. VALOR TOTAL\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"cnae\"}], \"id\": \"6. CNAE e Item da Lista de Serviços\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"serviços\"}], \"id\": \"7. VALORES E IMPOSTOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"dados\"}, {\"LOWER\": \"complementares\"}], \"id\": \"8. DADOS COMPLEMENTARES\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"outras\"}, {\"LOWER\": \"informações\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"criticas\"}], \"id\": \"9. OUTRAS INFORMAÇOES / CRITICAS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"observação\"},{\"ORTH\": \":\"}], \"id\": \"10. OBSERVACOES\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "patternsSecretarias = [{\"label\": \"secretaria\", \"pattern\": [{\"LOWER\": \"secretaria\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"fazenda\"},], \"id\": \"SECRETARIA\"}] \n",
    "\n",
    "\n",
    "patternsTipoDocumento = [\n",
    "                        {\"label\": \"tipo_documento\", \"pattern\": [{\"LOWER\": \"nota\"}, {\"LOWER\": \"fiscal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}, {\"LOWER\": \"eletrônica\"}, {\"LOWER\": \"-\"}, {\"LOWER\": \"nfs-e\"}], \"id\": \"NFS-e\"}\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsCampos = [\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"telefone\"},{\"ORTH\": \":\"}], \"id\": \"telefone\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"nome\"},{\"ORTH\": \"/\"},{\"LOWER\": \"razão\"},{\"LOWER\": \"social\"},{\"ORTH\": \":\"}], \"id\": \"razao_social\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"endereço\"},{\"ORTH\": \":\"}], \"id\": \"endereco\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"e\"},{\"ORTH\": \"-\"},{\"LOWER\": \"mail\"},{\"ORTH\": \":\"}], \"id\": \"email\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"e-mail\"}], \"id\": \"e_mail\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"inscrição\"},{\"LOWER\": \"municipal\"},{\"ORTH\": \":\"}], \"id\": \"inscricao_municipal\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"inscrição\"},{\"LOWER\": \"estadual\"},{\"ORTH\": \":\"}], \"id\": \"inscricao_estadual\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"rg\"},{\"ORTH\": \":\"}], \"id\": \"rg\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"nome\"},{\"LOWER\": \"de\"},{\"LOWER\": \"fantasia\"},{\"ORTH\": \":\"}], \"id\": \"nome_fantasia\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"cpf\"},{\"ORTH\": \"/\"},{\"LOWER\": \"cnpj\"},{\"ORTH\": \":\"}], \"id\": \"cpf_cnpj_com_mascara\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"exigibilidade\"},{\"LOWER\": \"iss\"}], \"id\": \"exigibilidade_iss\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"regime\"},{\"LOWER\": \"tributação\"}], \"id\": \"regime_tributacao\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"simples\"},{\"LOWER\": \"nacional\"}, {\"IS_TITLE\": \"False\"}], \"id\": \"simples_nacional\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"issqn\"},{\"LOWER\": \"retido\"}], \"id\": \"issqn_retido\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"local\"},{\"ORTH\": \".\"},{\"LOWER\": \"prestação\"},{\"LOWER\": \"serviço\"}], \"id\": \"local_pretacao_servico\"},\n",
    "                        {\"label\": \"campos\", \"pattern\": [{\"LOWER\": \"local\"},{\"LOWER\": \"incidência\"}], \"id\": \"local_incidencia\"},\n",
    "                        ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# patternsValores = [{\"label\": \"INSC_ESTADUAL\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"^\\d{8}$\"}}], \"id\": \"inscricao_estadual\"},\n",
    "#                    {\"label\": \"INSC_MUNICIPAL\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"^\\d{7}$\"}}], \"id\": \"inscricao_municipal\"},\n",
    "#                    {\"label\": \"CPF_CNPJ\", \"pattern\": [{\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}$\"}}], \"id\": \"cpf_cnpj_com_mascara\"}\n",
    "#                    ]\n",
    "\n",
    "\n",
    "\n",
    "patternsEncerradores = [{\"label\": \"encerrador\", \"pattern\": [{\"LOWER\": \"https\"},{\"ORTH\": \":\"}], \"id\": \"encerrador\"},\n",
    "                        {\"label\": \"encerrador\", \"pattern\": [{\"LOWER\": \"https://nfs-e.mage.rj.gov.br\"}], \"id\": \"encerrador\"}\n",
    "                        ] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patternsCnpj = [\n",
    "    {\n",
    "        \"label\": \"CNPJ\",\n",
    "        \"pattern\": [\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/$\"}},\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{4}-\\d{2}$\"}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "patterns = patternsPrefeitura + patternsSection + patternsSecretarias + patternsTipoDocumento + patternsEncerradores + patternsCampos\n",
    "\n",
    "\n",
    "# # XXX Processo para salvar entity ruler pattern para json\n",
    "\n",
    "# nome_entityruler_pattern_json = tipo_doc_work + \"_entity_ruler_pattern.json\"\n",
    "# entityruler_file_path = os.path.join(tipo_documento_patterns_path, nome_entityruler_pattern_json)\n",
    "\n",
    "# write_patterns_to_file(patterns=patterns, colors=colors, filename=entityruler_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# # XXX Processo de load de  patterns do Entity Ruler\n",
    "\n",
    "# entity_ruler_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('entity_ruler_pattern_path', 'valor_padrao')\n",
    "\n",
    "# patterns, colors = load_patterns_and_colors(entity_ruler_pattern_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>1.3</b> Tratando os Matchers patterns </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Matcher Patterns\n",
    "#======================================== 1. CABECALHO\n",
    "# 1. Número da Nota:\n",
    "numero_nota_pattern = [\n",
    "    {\"LOWER\": \"número\"},\n",
    "    {\"LOWER\": \"da\"},\n",
    "    {\"LOWER\": \"nota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True}\n",
    "]\n",
    "matcher.add(\"numero_nota_fiscal\", [numero_nota_pattern])\n",
    "\n",
    "\n",
    "# 2. Competência:\n",
    "competencia_pattern = [\n",
    "    {\"LOWER\": \"competência\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"?\"},\n",
    "    {\"ORTH\": {\"REGEX\": \"^[A-Z][a-z]+/[0-9]{4}$\"}}   \n",
    "]    \n",
    "matcher.add(\"competencia\", [competencia_pattern])\n",
    "\n",
    "# 3. Data e Hora de Emissão:\n",
    "data_hora_emissao_pattern = [\n",
    "    {\"LOWER\": \"data\"},\n",
    "    {\"LOWER\": \"e\"},\n",
    "    {\"LOWER\": \"hora\"},\n",
    "    {\"LOWER\": \"da\"},\n",
    "    {\"LOWER\": \"emissão\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"SHAPE\": \"dd/dd/dddd\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"SHAPE\": \"dd:dd:dd\"}\n",
    "]\n",
    "matcher.add(\"dt_hr_emissao\", [data_hora_emissao_pattern])\n",
    "\n",
    "# 4. Código de Verificação:\n",
    "codigo_verificacao_pattern = [\n",
    "    {\"LOWER\": \"código\"},\n",
    "    {\"LOWER\": \"verificação\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ASCII\": True, \"LENGTH\": 9}\n",
    "]\n",
    "matcher.add(\"codigo_verificacao\", [codigo_verificacao_pattern])\n",
    "\n",
    "\n",
    "#========================================  5. VALOR TOTAL\n",
    "valor_total_nota_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"total\"},\n",
    "    {\"LOWER\": \"da\", \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"nota\", \"OP\": \"?\"},\n",
    "    {\"TEXT\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_total_nota\", [valor_total_nota_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#======================================== 7. VALORES E IMPOSTOS\n",
    "\n",
    "# 1. VALOR_SERVICOS\n",
    "valor_servicos_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"serviços\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_servicos\", [valor_servicos_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 2. VALOR DEDUÇÃO:\n",
    "valor_deducao_1_pattern = [\n",
    "    {\"LOWER\": \"dedução\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_deducao\", [valor_deducao_1_pattern])\n",
    "\n",
    "# 2.1 VALOR DEDUÇÃO:\n",
    "valor_deducao_2_pattern = [\n",
    "    {\"LOWER\": \"dedução\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"Number=Sing\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_deducao\", [valor_deducao_2_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 2.2 DESC. INCOND1:\n",
    "valor_deducao_3_pattern= [\n",
    "    {\"LOWER\": \"dedução\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"}  \n",
    "]\n",
    "matcher.add(\"valor_deducao\", [valor_deducao_3_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3.0 DESC. INCOND:\n",
    "desc_incond_pattern = [\n",
    "    {\"LOWER\": \"incond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"}  \n",
    "]\n",
    "matcher.add(\"desc_incond\", [desc_incond_pattern])\n",
    "\n",
    "\n",
    "# 3.1 DESC. INCOND1:\n",
    "desc_incond_1_pattern = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"ORTH\": \".\"},\n",
    "    {\"LOWER\": \"incond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"}  \n",
    "]\n",
    "matcher.add(\"desc_incond\", [desc_incond_1_pattern])\n",
    "\n",
    "# 3.2 DESC. INCOND2:\n",
    "desc_incond_2_pattern = [\n",
    "    {\"LOWER\": \"base\"},\n",
    "    {\"LOWER\": \"de\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"}  \n",
    "]\n",
    "matcher.add(\"desc_incond\", [desc_incond_2_pattern])\n",
    "\n",
    "# 3.3 DESC. INCOND3:\n",
    "desc_incond_3_pattern = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"LOWER\": \"incond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}  \n",
    "]\n",
    "matcher.add(\"desc_incond\", [desc_incond_3_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4.1 BASE DE CÁLCULO:  PDF_P\n",
    "base_calculo_1_pattern = [\n",
    "    {\"LOWER\": \"base\"},\n",
    "    {\"LOWER\": \"de\"},\n",
    "    {\"LOWER\": \"cálculo\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"base_calculo\", [base_calculo_1_pattern])\n",
    "\n",
    "\n",
    "# 4.2 BASE DE CÁLCULO:  RASTER_PDF\n",
    "base_calculo_2_pattern = [\n",
    "    {\"LOWER\": \"calculo\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"base_calculo\", [base_calculo_2_pattern])\n",
    "\n",
    "\n",
    "# 5. Aliquota\n",
    "aliquota_pattern = [\n",
    "            {\"LOWER\": \"alíquota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"d\", \"OP\": \"?\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ]\n",
    "matcher.add(\"aliquota\", [aliquota_pattern])\n",
    "\n",
    "aliquota_1_pattern =  [\n",
    "            {\"LOWER\": \"alíquota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"d,dd\", \"OP\": \"?\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ]\n",
    "matcher.add(\"aliquota\", [aliquota_1_pattern])\n",
    "\n",
    "\n",
    "aliquota_2_pattern = [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"+\"},\n",
    "            {\"ORTH\": \"\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ]\n",
    "matcher.add(\"aliquota\", [aliquota_2_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 6. VALOR ISS:\n",
    "valor_iss_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_iss\", [valor_iss_pattern])\n",
    "\n",
    "\n",
    "# 7. VALOR ISS RETIDO:\n",
    "valor_iss_retido_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"LOWER\": \"retido\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_iss_retido\", [valor_iss_retido_pattern])\n",
    "\n",
    "\n",
    "# 8. DESC. COND:\n",
    "desc_cond_pattern = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"ORTH\": \".\"},\n",
    "    {\"LOWER\": \"cond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"desc_cond\", [desc_cond_pattern])\n",
    "\n",
    "\n",
    "# 9. VALOR PIS:\n",
    "valor_pis_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"pis\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_pis\", [valor_pis_pattern])\n",
    "\n",
    "\n",
    "# 10. VALOR COFINS:\n",
    "valor_cofins_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"cofins\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_cofins\", [valor_cofins_pattern])\n",
    "\n",
    "\n",
    "# 11. VALOR IR:\n",
    "valor_ir_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"ir\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_ir\", [valor_ir_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 12. VALOR INSS:\n",
    "valor_inss_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"inss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_inss\", [valor_inss_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 13. VALOR CSLL:\n",
    "valor_csll_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"csll\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_csll\", [valor_csll_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 14. OUTRAS RETENÇÕES:\n",
    "outras_retencoes_pattern = [\n",
    "    {\"LOWER\": \"outras\"},\n",
    "    {\"LOWER\": \"retenções\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"outras_retencoes\", [outras_retencoes_pattern])\n",
    "\n",
    "\n",
    "# 15. VALOR LÍQUIDO:\n",
    "valor_liquido_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"líquido\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"valor_liquido\", [valor_liquido_pattern])\n",
    "\n",
    "# # XXX Processo para salvar matcher pattern para json\n",
    "# nome_matches_pattern_json = tipo_doc_work + \"_matcher_pattern.json\"\n",
    "# path_matches_pattern_json = os.path.join(tipo_documento_patterns_path, nome_matches_pattern_json)\n",
    "# with open(path_matches_pattern_json, \"w\") as f:\n",
    "#     json.dump(matcher_pattern_dict, f)\n",
    "\n",
    "\n",
    "\n",
    "# # XXX Rotina para carregar e atribuir ao matcher os patterns do disco\n",
    "# matcher_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('matcher_pattern_path', 'valor_padrao')\n",
    "\n",
    "# matcher = Matcher(nlp.vocab)\n",
    "# # XXX Carregar matcher patterns do disco\n",
    "# with open(matcher_pattern_path, \"r\") as f:\n",
    "#     loaded_patterns = json.load(f)\n",
    "    \n",
    "# # Adicionar ao Matcher\n",
    "# for label, pattern in loaded_patterns.items():\n",
    "#     matcher.add(label, [pattern])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>1.4</b> Testes de templates e  patterns  </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Carregagando o sample documento do tipo de documento em execucao\n",
    "sample_text = tipo_documento_dict.get(tipo_doc_work, {}).get('sample_content', 'valor_padrao')\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = 'ab2457b7-ea5c-4191-acf0-bc8edc04879e'\n",
    "sample_text = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "doc = nlp(sample_text)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> <b>1.4.1</b> Entity Ruler Patterns  </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Aplicar a funçao show_ent_new para exibir o resultado\n",
    "doc, tokens, ents = show_ent_new(sample_text, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> <b>1.4.2</b> Matcher Patterns  </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sample_text)\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "spans = []\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    span.label_ = nlp.vocab.strings[match_id]  # Adicionar o label ao span\n",
    "    spans.append(span)\n",
    "    \n",
    "# Configuração de cores\n",
    "colors = {\n",
    "            \"numero_nota_fiscal\": \"orange\",\n",
    "            \"competencia\": \"lightblue\",\n",
    "            \"dt_hr_emissao\": \"lightblue\",\n",
    "            \"codigo_verificacao\": \"silver\",\n",
    "            \"valor_total_nota\": \"#EE8AF8\",  \n",
    "            \"ALIQUOTA2\": \"turquoise\",\n",
    "            \"VALOR_TOTAL\":\"linear-gradient(90deg, #2ADB5E, #1FA346)\",\n",
    "            \"VALOR_SERVICOS\":\"linear-gradient(90deg, #09D6FF, #08A0D1)\",\n",
    "            \"VALOR_DEDUCAO\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "            \"VALOR_DEDUCAO2\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "            \"VALOR_CSLL\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\",\n",
    "            \"VALOR_CSLL2\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\",\n",
    "            \"VALOR_INSS\": \"lightblue\",\n",
    "            \"VALOR_INSS2\": \"lightblue\",\n",
    "            \"BASE_CALCULO\": \"lightblue\",\n",
    "            \"VALOR_CSLL\": \"#FFEA7F\", # Laranja claro\n",
    "            \"INSC_MUNICIPAL\": \"#CCA10C\", # Terracota\n",
    "            \"CPF_CNPJ\": \"#CCA10C\", # Terracota\n",
    "            \"campos\": \"#AB9BFC\", # Roxo claro \n",
    "            \"OUTRAS_RETENCOES\": \"#7AECEC\", # Azul bem claro\n",
    "            \"VALOR_LIQUIDO\": \"#EE8AF8\", # Rosa medio\n",
    "            \"VALOR_CSLL\": \"silver\",\n",
    "            \"VALOR_IR\": \"orange\",\n",
    "            \"VALOR_COFINS\": \"lime\",\n",
    "            \"VALOR_PIS\":\"cyan\",\n",
    "            \"DESC_COND\": \"#AB9BFC\",\n",
    "            \"VALOR_ISS_RETIDO\": \"mint\",\n",
    "            \"VALOR_ISS\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "            \"BASE_DE_CALCULO\": \"salmon\",\n",
    "            \"DESC_INCOND\": \"#AB9BFC\",\n",
    "            \"DESC_INCOND1\": \"pink\",\n",
    "            \"VALOR_DEDUCAO\": \"white\",\n",
    "            \"endereco_site\": \"orange\",\n",
    "          }\n",
    "\n",
    "# Renderizar\n",
    "displacy.render([{'text': doc.text, 'ents': [{'start': span.start_char, 'end': span.end_char, 'label': span.label_} for span in spans]}], style='ent', manual=True, options={\"colors\": colors})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id:>30} | {span.text:>50} | {span.start_char:>5}  {span.end_char:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(texto_amostra)\n",
    "\n",
    "matches = matcher(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relaçao de valores encontrados - Matcher Patterns\n",
    "matches = matcher(doc1)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc1[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id:>30} | {span.text:>50} | {span.start_char:>5}  {span.end_char:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(texto_amostra)\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "spans = []\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    span.label_ = nlp.vocab.strings[match_id]  # Adicionar o label ao span\n",
    "    spans.append(span)\n",
    "    \n",
    "# Configuração de cores\n",
    "colors = {\n",
    "            \"numero_nota_fiscal\": \"orange\",\n",
    "            \"competencia\": \"lightblue\",\n",
    "            \"dt_hr_emissao\": \"lightblue\",\n",
    "            \"codigo_verificacao\": \"silver\",\n",
    "            \"valor_total_nota\": \"#EE8AF8\",  \n",
    "            \"ALIQUOTA2\": \"turquoise\",\n",
    "            \"VALOR_TOTAL\":\"linear-gradient(90deg, #2ADB5E, #1FA346)\",\n",
    "            \"VALOR_SERVICOS\":\"linear-gradient(90deg, #09D6FF, #08A0D1)\",\n",
    "            \"VALOR_DEDUCAO\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "            \"VALOR_DEDUCAO2\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "            \"VALOR_CSLL\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\",\n",
    "            \"VALOR_CSLL2\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\",\n",
    "            \"VALOR_INSS\": \"lightblue\",\n",
    "            \"VALOR_INSS2\": \"lightblue\",\n",
    "            \"BASE_CALCULO\": \"lightblue\",\n",
    "            \"VALOR_CSLL\": \"#FFEA7F\", # Laranja claro\n",
    "            \"INSC_MUNICIPAL\": \"#CCA10C\", # Terracota\n",
    "            \"CPF_CNPJ\": \"#CCA10C\", # Terracota\n",
    "            \"campos\": \"#AB9BFC\", # Roxo claro \n",
    "            \"OUTRAS_RETENCOES\": \"#7AECEC\", # Azul bem claro\n",
    "            \"VALOR_LIQUIDO\": \"#EE8AF8\", # Rosa medio\n",
    "            \"VALOR_CSLL\": \"silver\",\n",
    "            \"VALOR_IR\": \"orange\",\n",
    "            \"VALOR_COFINS\": \"lime\",\n",
    "            \"VALOR_PIS\":\"cyan\",\n",
    "            \"DESC_COND\": \"#AB9BFC\",\n",
    "            \"VALOR_ISS_RETIDO\": \"mint\",\n",
    "            \"VALOR_ISS\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\",\n",
    "            \"BASE_DE_CALCULO\": \"salmon\",\n",
    "            \"DESC_INCOND\": \"#AB9BFC\",\n",
    "            \"DESC_INCOND1\": \"pink\",\n",
    "            \"VALOR_DEDUCAO\": \"white\",\n",
    "            \"endereco_site\": \"orange\",\n",
    "          }\n",
    "\n",
    "# Renderizar\n",
    "displacy.render([{'text': doc.text, 'ents': [{'start': span.start_char, 'end': span.end_char, 'label': span.label_} for span in spans]}], style='ent', manual=True, options={\"colors\": colors})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra = \"Inscrição Municipal: 952538 Telefone: 2297268232.. Inscrição Estadual: Nome/Razão Social: MEDSORIA CLINICA \"\n",
    "doc1 = nlp(amostra)\n",
    "\n",
    "\n",
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc1:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization for tokens \n",
    "lemmatization = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"Texto\",\"Lemma\", \"Tag\", \"Tag_explainned\", \"token_POS\", \"POS_explainned\", \"dep\", \"T. Head\", \"dep explained\"])\n",
    "i = 0\n",
    "for token in doc1:\n",
    "    lemmatization.loc[i,\"id\"] = token.i\n",
    "    lemmatization.loc[i,\"Texto\"] = token.text\n",
    "    lemmatization.loc[i,\"Lemma\"] = token.lemma_\n",
    "    lemmatization.loc[i,\"Tag\"] = token.tag_\n",
    "    lemmatization.loc[i,\"Tag_explainned\"] = spacy.explain(token.tag_)\n",
    "    lemmatization.loc[i,\"token_POS\"] = token.pos_\n",
    "    lemmatization.loc[i,\"POS_explainned\"] = spacy.explain(token.pos_)\n",
    "    lemmatization.loc[i,\"dep\"] = token.dep_\n",
    "    lemmatization.loc[i,\"T. Head\"] = token.head.text\n",
    "    lemmatization.loc[i,\"dep explained\"] = token.morph\n",
    "    \n",
    "    i = i+1\n",
    "lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc1, style=\"dep\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> <b>1.3</b> Criando novos patterns </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def atualiza_df_root_pipe(num_head):\n",
    "#     # 4. XXX Ler a planilha e cria df_documento_recebido\n",
    "#     df_root_pipe = pd.read_excel(file_path_root_pipe)\n",
    "\n",
    "\n",
    "#     # 5. XXX  Ajustar o indice\n",
    "#     df_root_pipe.set_index('document_unique_id', inplace=True)\n",
    "    \n",
    "#     return df_root_pipe.head(num_head)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Funcao simples para atualizar templates\n",
    "# frames_nf_v4_df = importa_models()\n",
    "\n",
    "# # funçao de atualizaçao do df_root_pipe\n",
    "# atualiza_df_root_pipe(num_head=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = frames_nf_v4_df[(frames_nf_v4_df['type'] == f_type) & (frames_nf_v4_df['de_para_pm'] == de_para_pm)]\n",
    "model_map = resultado.iloc[0]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"set_cnpj_attribute\") # Adicione esta etapa se você quiser definir o atributo manualmente\n",
    "\n",
    "nlp.add_pipe(\"apply_cnpj_matcher\")  # Adicione esta etapa para aplicar o matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> <b>2.0</b> Mapeamento e Extracao  </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta e o principio da melhor funcao do mundo\n",
    "def extracao_pipeline(qualquer_df, doc_content, fase, atividade, status, debug=False, prestador=True, tomador=True, servicos=True, total=True, cnae=True, valores_impostos=True, complementares=True, outras_informacoes=True, observacoes=True):\n",
    "    \n",
    "    doc_info = {}\n",
    "    resumo = {}\n",
    "    row_teste_info = []\n",
    "    time_now = cron.timenow_pt_BR()\n",
    "    func_fase = fase\n",
    "    func_atividade = atividade\n",
    "    func_status = status\n",
    "    lista_dicts = []\n",
    "    conf_processo = {}\n",
    "    lista_conferencia = []\n",
    "   \n",
    "    i = 1\n",
    "    for idx, row in qualquer_df.iterrows():\n",
    "        dados_iniciais = {}\n",
    "        row_info = row.to_dict()\n",
    "        message_erro = []\n",
    "        # 1. Mapeamento de informacoes do DF\n",
    "        map_document_unique_id = idx\n",
    "        map_seq = row['seq']\n",
    "        map_batch_name = row['batch']\n",
    "        map_fase_processo = row['fase_processo']\n",
    "        map_nome_atividade = row['nome_atividade']\n",
    "        map_status_documento = row['status_documento']\n",
    "        map_original_file_name = row['original_file_name']\n",
    "        map_directory = row['directory']\n",
    "        map_one_page = row['one_page']\n",
    "        map_palavra_chave = row['palavra_chave']\n",
    "        map_document_tag = row['document_tag']\n",
    "        map_action_item = row['action_item']\n",
    "        map_pdf_pesquisavel = row['pdf_pesquisavel']\n",
    "        map_level = row['level']\n",
    "        file_path = row['file_path']\n",
    "        row_info['document_unique_id'] = map_document_unique_id\n",
    "    \n",
    "        # XXX Nivel 1 - Definindo que documentos serao tratados   \n",
    "        if map_status_documento == 'PREPROCESS_EXTRACT':\n",
    "            print(f'seq: {i:>3} | {batch_name} | idx: {idx} | pdf pesq.: {map_pdf_pesquisavel} | status_documento: {map_status_documento} | processando doc: {map_original_file_name} ')\n",
    "            # 1. Buscando o texto do documento pelo doc_content\n",
    "            texto_dict = doc_content.get(map_document_unique_id, {}).get('content', 'valor_padrao')\n",
    "            \n",
    "            # 2. XXX IMPORTANTE - Efetuo a busca de entidades e efetuo a tokenizaÇao do documento\n",
    "            doc, tokens, ents = show_ent_new(texto_dict, patterns=patterns)\n",
    "            matches = matcher(doc)\n",
    "                    \n",
    "            prefeitura_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"nome_prefeitura\"][0]\n",
    "            de_para_pm = [ent.id_ for ent in doc.ents if ent.label_ == \"nome_prefeitura\"][0]\n",
    "            secretaria_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"secretaria\"][0]\n",
    "            tipo_documento_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"tipo_documento\"][0] \n",
    "         \n",
    "            f_type = 'document'\n",
    "            ic(f_type)\n",
    "            ic(de_para_pm)\n",
    "            \n",
    "            \n",
    "            # cores = \n",
    "            # resultado = utl.filtrar_df(frames_nf_v4_df, type=f_type, de_para_pm=de_para_pm)\n",
    "            \n",
    "            resultado = frames_nf_v4_df[(frames_nf_v4_df['type'] == f_type) & (frames_nf_v4_df['de_para_pm'] == de_para_pm)]\n",
    "            \n",
    "            ic(resultado)\n",
    "            model_map = resultado.iloc[0]['model']\n",
    "            # model_map = resultado['model'].values[0]\n",
    "        \n",
    "           \n",
    "            section = \"1. CABECALHO\"\n",
    "            valores = {}\n",
    "            mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "            context_mapping = \"data_cabecalho\"\n",
    "            def_replace = True\n",
    "            \n",
    "            if map_pdf_pesquisavel == False:\n",
    "                imagem_gray, image_resized_name = convert_resize_gray(map_original_file_name, file_path, image_resized_path)\n",
    "                imagem_gray_rgb = imagem_gray.convert(\"RGB\")\n",
    "                imagem_gray_np = np.array(imagem_gray_rgb)\n",
    "                doc_content[map_document_unique_id]['image_np'] = imagem_gray_np\n",
    "\n",
    "                # vou tratar o texto do cabecalho\n",
    "                texto_cabecalho_PDF_Raster = extrac_cabecalho_R_PDF(idx, row, row_info, doc_content, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "                #print(f'\\n1. texto_cabechalho_PDF_Raster: {texto_cabechalho_PDF_Raster}\\n')\n",
    "                # Ajusto o texto todo\n",
    "                if texto_cabecalho_PDF_Raster:\n",
    "                    texto_recomposto = ajusta_texto_Raster_P(idx, row, map_document_unique_id, texto_dict, texto_cabecalho_PDF_Raster)\n",
    "                    if debug:\n",
    "                        print(f'\\n2. texto_dict: {texto_recomposto}\\n')\n",
    "                    # Atualizao do doc_content\n",
    "                    doc_content[map_document_unique_id]['content'] = texto_recomposto\n",
    "                    texto_dict = texto_recomposto    \n",
    "            \n",
    "            #matcher = Matcher(nlp.vocab)\n",
    "            matches = matcher(doc)\n",
    "            \n",
    "            # XXX Rotina para carregar e atribuir ao matcher os patterns do disco\n",
    "            matcher_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('matcher_pattern_path', 'valor_padrao')\n",
    "            # XXX Carregar matcher patterns do disco\n",
    "            with open(matcher_pattern_path, \"r\") as f:\n",
    "                loaded_patterns = json.load(f)\n",
    "                \n",
    "            # Adicionar ao Matcher\n",
    "            for label, pattern in loaded_patterns.items():\n",
    "                matcher.add(label, [pattern])  \n",
    "\n",
    "            doc, tokens, ents = show_ent_new(texto_dict, patterns=patterns)\n",
    "            matches = matcher(doc)\n",
    "            \n",
    "            # 3. XXX Mapeamento dados do cabecalho\n",
    "            valores = mapeia_cabecalho(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            \n",
    "            if debug:\n",
    "                print(f'\\nvalores: {valores}\\n')\n",
    "            \n",
    "            row_info['model'] = model_map\n",
    "            row_info['de_para_pm'] = de_para_pm\n",
    "            row_info['tipo_nota_fiscal'] = tipo_documento_map\n",
    "            row_info['secretaria'] = secretaria_map\n",
    "            row_info['prefeitura'] = prefeitura_map\n",
    "            if debug:\n",
    "                print(f'1. row_info: {row_info}\\n')\n",
    "            \n",
    "            row_info.update(valores)\n",
    "            information_row_info = \"Este e apenas um comeco - mas bem comeco mesmo\"\n",
    "            action_item_row_info = 'CONTINUE_PROCESS'\n",
    "\n",
    "            # 4. XXX Mapeamento dados do prestador\n",
    "            valores = {}\n",
    "            valores = mapeia_prestador(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            if valores:\n",
    "                row_info.update(valores)\n",
    "                \n",
    "            # 5. XXX Mapeamento dados do tomador    \n",
    "            valores = {}    \n",
    "            valores = mapeia_tomador(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            if valores:\n",
    "                row_info.update(valores)\n",
    "            \n",
    "            # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "            texto = doc_content.get(idx, {}).get('content', 'valor_padrao')\n",
    "            servicos_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "            valor_total_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '5. VALOR TOTAL'][0]\n",
    "            descr_servicos = texto[servicos_end_char:valor_total_start_char]\n",
    "            row_info['discriminacao_servicos'] = descr_servicos     \n",
    "\n",
    "            matches = matcher(doc)\n",
    "            \n",
    "            # XXX Rotina para carregar e atribuir ao matcher os patterns do disco\n",
    "            matcher_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('matcher_pattern_path', 'valor_padrao')\n",
    "\n",
    "            # XXX Carregar matcher patterns do disco\n",
    "            with open(matcher_pattern_path, \"r\") as f:\n",
    "                loaded_patterns = json.load(f)\n",
    "                \n",
    "            # Adicionar ao Matcher\n",
    "            for label, pattern in loaded_patterns.items():\n",
    "                matcher.add(label, [pattern])  \n",
    "\n",
    "            doc, tokens, ents = show_ent_new(texto_dict, patterns=patterns)\n",
    "            matches = matcher(doc)\n",
    "            \n",
    "            # 6. Mapeia cnae e Itens\n",
    "            valores = {}    \n",
    "            valores = mapeia_cnae_item(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            if valores:\n",
    "                row_info.update(valores)\n",
    "            \n",
    "            \n",
    "            # 7. Mapeia valores\n",
    "            valores = {}                     \n",
    "            valores = mapeia_campos_valores(idx, row, row_info, doc_content, doc, matches, section, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            if valores:\n",
    "                row_info.update(valores)\n",
    "            \n",
    "            \n",
    "            # 8. DADOS COMPLEMENTARES\n",
    "            dados_complementares_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '8. DADOS COMPLEMENTARES'][0]\n",
    "            outras_informacoes_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '9. OUTRAS INFORMAÇOES / CRITICAS'][0]\n",
    "            dados_complementares = texto[dados_complementares_end_char:outras_informacoes_start_char]\n",
    "            row_info['dados_complementares'] = dados_complementares\n",
    "            \n",
    "           # 9. Mapeia Informaçoes criticas\n",
    "            valores = {}    \n",
    "            valores = mapeia_informacoes_criticas(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            if valores:\n",
    "                row_info.update(valores)     \n",
    "                \n",
    "            \n",
    "            # 10. OBSERVACOES\n",
    "            observacoes_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '10. OBSERVACOES'][0]\n",
    "            try:\n",
    "                encerrador_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'encerrador'][0]\n",
    "            except IndexError:\n",
    "                encerrador_start_char = None \n",
    "            if encerrador_start_char == None:\n",
    "                observacao = texto[observacoes_end_char:]\n",
    "            else:           \n",
    "                observacao = texto[observacoes_end_char:encerrador_start_char]\n",
    "            row_info['observacao'] = observacao\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "            lista_dicts.append(row_info)\n",
    "            i += 1\n",
    "            # continue\n",
    "\n",
    "        \n",
    "        elif map_status_documento == 'NO_PROCESS' or map_status_documento == 'root_analise':\n",
    "            msg = (f'Documento nao sera tratado neste escopo: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory}')\n",
    "            row_info['action_item'] = \"NO_PROCESS\"    \n",
    "            row_info['informations'] = msg \n",
    "            lista_dicts.append(row_info)\n",
    "            #print(f'\\nprocessando: batch: {batch_name} | seq: {i} | file_name: {map_original_file_name:>40} | idx: {idx} - Nao sera processado')\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "    #logging.info(f'processamento finalizado para: {batch_name}') \n",
    "    print(f'\\n\\nprocessamento de {i - 1} documentos')\n",
    "    novo_df = pd.DataFrame(lista_dicts)\n",
    "  \n",
    "    return novo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq:   2 | Batch_23 | idx: 27df9e70-b5fb-45b7-8f59-0c04ed9728e2 | pdf pesq.: 0.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 1.pdf \n",
      "seq:   4 | Batch_23 | idx: ab2457b7-ea5c-4191-acf0-bc8edc04879e | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 2023 -5.pdf \n",
      "seq:   5 | Batch_23 | idx: b6b5af8f-78dc-4627-9322-9c3b70f46a48 | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 2023 -7.pdf \n",
      "seq:   6 | Batch_23 | idx: d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 2023 -4.pdf \n",
      "seq:   7 | Batch_23 | idx: ef2477eb-67ca-43bf-bab4-826d872d47e7 | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 2023 -6.pdf \n",
      "seq:   8 | Batch_23 | idx: fd74ace6-6582-4e71-ada9-f21760846ade | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 2023 -3.pdf \n",
      "seq:   9 | Batch_23 | idx: c8a7cd74-931c-4b38-814f-779874d69417 | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 2023 -8.pdf \n",
      "seq:  10 | Batch_23 | idx: 95df6a78-d1f0-4c98-b349-96f1e9d6b10c | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: 31-07.pdf \n",
      "seq:  11 | Batch_23 | idx: 6184149d-ac46-473a-8246-a39b2a9f302d | pdf pesq.: 1.0 | status_documento: PREPROCESS_EXTRACT | processando doc: ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRYmgxKBy0XaQ7M2xYrrH8asjKXSfK1z9f4bSQaT1DI5gppkc3aHRHnhAvAAwBjUamKPilUuXpYdD2ovRXzk=.pdf \n",
      "\n",
      "\n",
      "processamento de 13 documentos\n"
     ]
    }
   ],
   "source": [
    "# analisar_pdf_pesquisavel\n",
    "fase = 'analise'\n",
    "atividade = 'PREPROCESS' \n",
    "status = 'PREPROCESS_EXTRACT'\n",
    "lista_dicts = []\n",
    "#logging.info(f'Execuçao do pipeline para {batch_name} | df_root_pipe: {file_path_root_pipe} fase: {fase} atividade: {atividade} status: {status}  template: {ver}')\n",
    "# 1. Processar somente dados iniciais e cabeçalho\n",
    "df_result_pipe = extracao_pipeline(df_root_pipe, doc_content, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>date_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>sigla_tipo</th>\n",
       "      <th>fase_processo</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>status_documento</th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>...</th>\n",
       "      <th>valor_liquido</th>\n",
       "      <th>dados_complementares</th>\n",
       "      <th>exigibilidade_iss</th>\n",
       "      <th>regime_tributacao</th>\n",
       "      <th>simples_nacional</th>\n",
       "      <th>issqn_retido</th>\n",
       "      <th>local_prestacao_servico</th>\n",
       "      <th>local_incidencia</th>\n",
       "      <th>observacao</th>\n",
       "      <th>desc_incond</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>2</td>\n",
       "      <td>26/09/2023 16:16:39</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>...</td>\n",
       "      <td>252836.00</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim (2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Magé - RJ</td>\n",
       "      <td>Magé - RJ</td>\n",
       "      <td>- Prestador Optante do Simples Nacional (Alíq...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>4</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1469.32</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim ( 2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>5</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>5706.88</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim ( 2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c</th>\n",
       "      <td>6</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>4280.16</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim ( 2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef2477eb-67ca-43bf-bab4-826d872d47e7</th>\n",
       "      <td>7</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>5706.88</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim ( 2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd74ace6-6582-4e71-ada9-f21760846ade</th>\n",
       "      <td>8</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>4532.39</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim ( 2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c8a7cd74-931c-4b38-814f-779874d69417</th>\n",
       "      <td>9</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>7133.60</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Sociedade Limitada</td>\n",
       "      <td>Sim ( 2,01% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95df6a78-d1f0-4c98-b349-96f1e9d6b10c</th>\n",
       "      <td>10</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>...</td>\n",
       "      <td>1200.00</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Microempresário Individual (MEI)</td>\n",
       "      <td>Sim ( 0% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Rio de Janeiro - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184149d-ac46-473a-8246-a39b2a9f302d</th>\n",
       "      <td>11</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>...</td>\n",
       "      <td>300.00</td>\n",
       "      <td></td>\n",
       "      <td>Exigivel</td>\n",
       "      <td>Microempresário Individual (MEI)</td>\n",
       "      <td>Sim ( 0% )</td>\n",
       "      <td>Não</td>\n",
       "      <td>Rio de Janeiro - RJ</td>\n",
       "      <td>Mesquita - RJ</td>\n",
       "      <td>LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>1</td>\n",
       "      <td>26/09/2023 16:16:39</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>3</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b1c342f-8049-410f-957b-fd1bf0ffc8c7</th>\n",
       "      <td>12</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3f115ed4-885f-4d2a-b2d5-c42da4348d42</th>\n",
       "      <td>13</td>\n",
       "      <td>26/09/2023 16:16:50</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      seq            date_time     batch  \\\n",
       "document_unique_id                                                         \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2    2  26/09/2023 16:16:39  Batch_23   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    4  26/09/2023 16:16:50  Batch_23   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    5  26/09/2023 16:16:50  Batch_23   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    6  26/09/2023 16:16:50  Batch_23   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    7  26/09/2023 16:16:50  Batch_23   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    8  26/09/2023 16:16:50  Batch_23   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    9  26/09/2023 16:16:50  Batch_23   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c   10  26/09/2023 16:16:50  Batch_23   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d   11  26/09/2023 16:16:50  Batch_23   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357    1  26/09/2023 16:16:39  Batch_23   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    3  26/09/2023 16:16:50  Batch_23   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7   12  26/09/2023 16:16:50  Batch_23   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42   13  26/09/2023 16:16:50  Batch_23   \n",
       "\n",
       "                                     sigla_tipo fase_processo nome_atividade  \\\n",
       "document_unique_id                                                             \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2      nfs_e       analise   scan_analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e      nfs_e       analise   scan_analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48      nfs_e       analise   scan_analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c      nfs_e       analise   scan_analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7      nfs_e       analise   scan_analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade      nfs_e       analise   scan_analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417      nfs_e       analise   scan_analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c      nfs_e       analise   scan_analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d      nfs_e       analise   scan_analise   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357      nfs_e       analise   scan_analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48      nfs_e       analise   scan_analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7      nfs_e       analise   scan_analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42      nfs_e       analise   scan_analise   \n",
       "\n",
       "                                        status_documento acao_executada  \\\n",
       "document_unique_id                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  PREPROCESS_EXTRACT        Analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  PREPROCESS_EXTRACT        Analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  PREPROCESS_EXTRACT        Analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  PREPROCESS_EXTRACT        Analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  PREPROCESS_EXTRACT        Analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  PREPROCESS_EXTRACT        Analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  PREPROCESS_EXTRACT        Analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  PREPROCESS_EXTRACT        Analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  PREPROCESS_EXTRACT        Analise   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357        root_analise        Analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48        root_analise        Analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7        root_analise        Analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42        root_analise        Analise   \n",
       "\n",
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                              1.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                        2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                        2023 -7.pdf   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                        2023 -4.pdf   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                        2023 -6.pdf   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                        2023 -3.pdf   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                        2023 -8.pdf   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                          31-07.pdf   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     MESQUITA_PDF_31282023_2258.zip   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     Livro de Registro do ISSQN.pdf   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  ...  valor_liquido  \\\n",
       "document_unique_id                              ...                  \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste  ...      252836.00   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871  ...        1469.32   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871  ...        5706.88   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    159871  ...        4280.16   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    159871  ...        5706.88   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    159871  ...        4532.39   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    159871  ...        7133.60   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    160014  ...        1200.00   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    160014  ...         300.00   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir  ...            NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964  ...            NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    126623  ...            NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    138565  ...            NaN   \n",
       "\n",
       "                                      dados_complementares  exigibilidade_iss  \\\n",
       "document_unique_id                                                              \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                 Exigivel   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                 Exigivel   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                 Exigivel   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                 Exigivel   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                 Exigivel   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                 Exigivel   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                 Exigivel   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                 Exigivel   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d                                 Exigivel   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                   NaN                NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                   NaN                NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                   NaN                NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                   NaN                NaN   \n",
       "\n",
       "                                                     regime_tributacao  \\\n",
       "document_unique_id                                                       \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                Sociedade Limitada   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                Sociedade Limitada   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                Sociedade Limitada   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                Sociedade Limitada   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                Sociedade Limitada   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                Sociedade Limitada   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                Sociedade Limitada   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  Microempresário Individual (MEI)   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  Microempresário Individual (MEI)   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                               NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                               NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                               NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                               NaN   \n",
       "\n",
       "                                     simples_nacional issqn_retido  \\\n",
       "document_unique_id                                                   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     Sim (2,01% )          Não   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    Sim ( 2,01% )          Não   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    Sim ( 2,01% )          Não   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    Sim ( 2,01% )          Não   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    Sim ( 2,01% )          Não   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    Sim ( 2,01% )          Não   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    Sim ( 2,01% )          Não   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c       Sim ( 0% )          Não   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d       Sim ( 0% )          Não   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357              NaN          NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48              NaN          NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7              NaN          NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42              NaN          NaN   \n",
       "\n",
       "                                     local_prestacao_servico  \\\n",
       "document_unique_id                                             \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2               Magé - RJ   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e           Mesquita - RJ   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48           Mesquita - RJ   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c           Mesquita - RJ   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7           Mesquita - RJ   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade           Mesquita - RJ   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417           Mesquita - RJ   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c     Rio de Janeiro - RJ   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d     Rio de Janeiro - RJ   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                     NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                     NaN   \n",
       "\n",
       "                                      local_incidencia  \\\n",
       "document_unique_id                                       \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2         Magé - RJ   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e     Mesquita - RJ   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48     Mesquita - RJ   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c     Mesquita - RJ   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7     Mesquita - RJ   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade     Mesquita - RJ   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417     Mesquita - RJ   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c     Mesquita - RJ   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d     Mesquita - RJ   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357               NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48               NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7               NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42               NaN   \n",
       "\n",
       "                                                                             observacao  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2   - Prestador Optante do Simples Nacional (Alíq...   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d   LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 ...   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                                                NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                                                NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                                                NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                                                NaN   \n",
       "\n",
       "                                     desc_incond  \n",
       "document_unique_id                                \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2         NaN  \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e         0.0  \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48         0.0  \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c         0.0  \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7         0.0  \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade         0.0  \n",
       "c8a7cd74-931c-4b38-814f-779874d69417         0.0  \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c         0.0  \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d         0.0  \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357         NaN  \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48         NaN  \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7         NaN  \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42         NaN  \n",
       "\n",
       "[13 rows x 76 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. XXX Volto novamente o indice do DF IMPORTANTE\n",
    "df_result_pipe.set_index('document_unique_id', inplace=True)\n",
    "\n",
    "ordem_status = ['PREPROCESS_EXTRACT', 'NO_PROCESS', 'root_analise']\n",
    "ordem_action_item = ['CONTINUE_PROCESS', 'BREAK_PROCESS', 'NO_PROCESS']\n",
    "\n",
    "df_result_pipe['status_documento'] = pd.Categorical(df_result_pipe['status_documento'], categories=ordem_status, ordered=True)\n",
    "df_result_pipe['action_item'] = pd.Categorical(df_result_pipe['action_item'], categories=ordem_action_item, ordered=True)\n",
    "\n",
    "df_result_pipe.sort_values(by=['status_documento', 'action_item', 'seq'], ascending=[True, True, True], inplace=True)\n",
    "\n",
    "df_result_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>one_page</th>\n",
       "      <th>pages</th>\n",
       "      <th>pdf_pesquisavel</th>\n",
       "      <th>score</th>\n",
       "      <th>palavra_chave</th>\n",
       "      <th>document_tag</th>\n",
       "      <th>action_item</th>\n",
       "      <th>status_documento</th>\n",
       "      <th>valor_total_nota</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>252836.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932860</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>1469.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>5706.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c</th>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>4280.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef2477eb-67ca-43bf-bab4-826d872d47e7</th>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>5706.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd74ace6-6582-4e71-ada9-f21760846ade</th>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934921</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>4532.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c8a7cd74-931c-4b38-814f-779874d69417</th>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>7133.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95df6a78-d1f0-4c98-b349-96f1e9d6b10c</th>\n",
       "      <td>Analise</td>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>1200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184149d-ac46-473a-8246-a39b2a9f302d</th>\n",
       "      <td>Analise</td>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>Analise</td>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zip</td>\n",
       "      <td>doc_zip</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>Analise</td>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>livro</td>\n",
       "      <td>prov_livro_registro</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b1c342f-8049-410f-957b-fd1bf0ffc8c7</th>\n",
       "      <td>Analise</td>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473714</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3f115ed4-885f-4d2a-b2d5-c42da4348d42</th>\n",
       "      <td>Analise</td>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     acao_executada  \\\n",
       "document_unique_id                                    \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2        Analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e        Analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48        Analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c        Analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7        Analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade        Analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417        Analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c        Analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d        Analise   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357        Analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48        Analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7        Analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42        Analise   \n",
       "\n",
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                              1.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                        2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                        2023 -7.pdf   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                        2023 -4.pdf   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                        2023 -6.pdf   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                        2023 -3.pdf   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                        2023 -8.pdf   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                          31-07.pdf   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     MESQUITA_PDF_31282023_2258.zip   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     Livro de Registro do ISSQN.pdf   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  one_page  pages  \\\n",
       "document_unique_id                                                \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste      True    1.0   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871      True    1.0   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871      True    1.0   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    159871      True    1.0   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    159871      True    1.0   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    159871      True    1.0   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    159871      True    1.0   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    160014      True    1.0   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    160014      True    1.0   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir     False    NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964     False    4.0   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    126623      True    1.0   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    138565      True    1.0   \n",
       "\n",
       "                                      pdf_pesquisavel     score palavra_chave  \\\n",
       "document_unique_id                                                              \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2              0.0  0.716463       default   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e              1.0  0.932860       default   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48              1.0  0.932562       default   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c              1.0  1.000000       default   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7              1.0  0.936102       default   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade              1.0  0.934921       default   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417              1.0  0.932562       default   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c              1.0  0.817916       default   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d              1.0  0.809813       default   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357              NaN       NaN           zip   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48              NaN       NaN         livro   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7              1.0  0.473714       default   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42              1.0  0.423344       default   \n",
       "\n",
       "                                             document_tag action_item  \\\n",
       "document_unique_id                                                      \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     prov_nota_fiscal         NaN   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e     prov_nota_fiscal         NaN   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48     prov_nota_fiscal         NaN   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c     prov_nota_fiscal         NaN   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7     prov_nota_fiscal         NaN   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade     prov_nota_fiscal         NaN   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417     prov_nota_fiscal         NaN   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c     prov_nota_fiscal         NaN   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d     prov_nota_fiscal         NaN   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357              doc_zip  NO_PROCESS   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  prov_livro_registro  NO_PROCESS   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7     prov_nota_fiscal  NO_PROCESS   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42     prov_nota_fiscal  NO_PROCESS   \n",
       "\n",
       "                                        status_documento  valor_total_nota  \n",
       "document_unique_id                                                          \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  PREPROCESS_EXTRACT         252836.00  \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  PREPROCESS_EXTRACT           1469.32  \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  PREPROCESS_EXTRACT           5706.88  \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  PREPROCESS_EXTRACT           4280.16  \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  PREPROCESS_EXTRACT           5706.88  \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  PREPROCESS_EXTRACT           4532.39  \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  PREPROCESS_EXTRACT           7133.60  \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  PREPROCESS_EXTRACT           1200.00  \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  PREPROCESS_EXTRACT            300.00  \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357        root_analise               NaN  \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48        root_analise               NaN  \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7        root_analise               NaN  \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42        root_analise               NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf0 = df_result_pipe[['acao_executada', 'original_file_name', 'directory', 'one_page', 'pages', 'pdf_pesquisavel', 'score', 'palavra_chave', 'document_tag','action_item','status_documento','valor_total_nota']]\n",
    "df_conf0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>2.3</b> Conferencia Extracao </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>sigla_tipo</th>\n",
       "      <th>fase_processo</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>pdf_pesquisavel</th>\n",
       "      <th>score</th>\n",
       "      <th>pages</th>\n",
       "      <th>document_tag</th>\n",
       "      <th>action_item</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef2477eb-67ca-43bf-bab4-826d872d47e7</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd74ace6-6582-4e71-ada9-f21760846ade</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c8a7cd74-931c-4b38-814f-779874d69417</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95df6a78-d1f0-4c98-b349-96f1e9d6b10c</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184149d-ac46-473a-8246-a39b2a9f302d</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doc_zip</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>prov_livro_registro</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b1c342f-8049-410f-957b-fd1bf0ffc8c7</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3f115ed4-885f-4d2a-b2d5-c42da4348d42</th>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         batch sigla_tipo fase_processo  \\\n",
       "document_unique_id                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  Batch_23      nfs_e       analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  Batch_23      nfs_e       analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  Batch_23      nfs_e       analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  Batch_23      nfs_e       analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  Batch_23      nfs_e       analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  Batch_23      nfs_e       analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  Batch_23      nfs_e       analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  Batch_23      nfs_e       analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  Batch_23      nfs_e       analise   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  Batch_23      nfs_e       analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  Batch_23      nfs_e       analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7  Batch_23      nfs_e       analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42  Batch_23      nfs_e       analise   \n",
       "\n",
       "                                     nome_atividade nome_atividade  \\\n",
       "document_unique_id                                                   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2   scan_analise   scan_analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e   scan_analise   scan_analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48   scan_analise   scan_analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c   scan_analise   scan_analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7   scan_analise   scan_analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade   scan_analise   scan_analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417   scan_analise   scan_analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c   scan_analise   scan_analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d   scan_analise   scan_analise   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357   scan_analise   scan_analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48   scan_analise   scan_analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7   scan_analise   scan_analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42   scan_analise   scan_analise   \n",
       "\n",
       "                                     acao_executada  \\\n",
       "document_unique_id                                    \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2        Analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e        Analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48        Analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c        Analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7        Analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade        Analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417        Analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c        Analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d        Analise   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357        Analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48        Analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7        Analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42        Analise   \n",
       "\n",
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                              1.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                        2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                        2023 -7.pdf   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                        2023 -4.pdf   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                        2023 -6.pdf   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                        2023 -3.pdf   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                        2023 -8.pdf   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                          31-07.pdf   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     MESQUITA_PDF_31282023_2258.zip   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     Livro de Registro do ISSQN.pdf   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  pdf_pesquisavel     score  \\\n",
       "document_unique_id                                                          \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste              0.0  0.716463   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871              1.0  0.932860   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871              1.0  0.932562   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    159871              1.0  1.000000   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    159871              1.0  0.936102   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    159871              1.0  0.934921   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    159871              1.0  0.932562   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    160014              1.0  0.817916   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    160014              1.0  0.809813   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir              NaN       NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964              NaN       NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    126623              1.0  0.473714   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    138565              1.0  0.423344   \n",
       "\n",
       "                                      pages         document_tag action_item  \n",
       "document_unique_id                                                            \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2    1.0     prov_nota_fiscal         NaN  \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    1.0     prov_nota_fiscal         NaN  \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    1.0     prov_nota_fiscal         NaN  \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    1.0     prov_nota_fiscal         NaN  \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    1.0     prov_nota_fiscal         NaN  \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    1.0     prov_nota_fiscal         NaN  \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    1.0     prov_nota_fiscal         NaN  \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    1.0     prov_nota_fiscal         NaN  \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    1.0     prov_nota_fiscal         NaN  \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357    NaN              doc_zip  NO_PROCESS  \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    4.0  prov_livro_registro  NO_PROCESS  \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    1.0     prov_nota_fiscal  NO_PROCESS  \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    1.0     prov_nota_fiscal  NO_PROCESS  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Dados basicos do documento\n",
    "df_conf0 = df_result_pipe[['batch', 'sigla_tipo', 'fase_processo', 'nome_atividade', 'nome_atividade', 'acao_executada', 'original_file_name', 'directory', 'pdf_pesquisavel', 'score', 'pages', 'document_tag', 'action_item']]\n",
    "df_conf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>pdf_pesquisavel</th>\n",
       "      <th>model</th>\n",
       "      <th>tipo_nota_fiscal</th>\n",
       "      <th>secretaria</th>\n",
       "      <th>prefeitura</th>\n",
       "      <th>de_para_pm</th>\n",
       "      <th>numero_nota_fiscal</th>\n",
       "      <th>competencia</th>\n",
       "      <th>dt_hr_emissao</th>\n",
       "      <th>codigo_verificacao</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MAGE</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MAGE</td>\n",
       "      <td>PM_MAGE</td>\n",
       "      <td>1</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>31/07/2023 17:29:00</td>\n",
       "      <td>4ADEE6A7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20235</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:13:00</td>\n",
       "      <td>92ED36652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20237</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:19:00</td>\n",
       "      <td>C45A7FCE4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c</th>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20234</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:11:00</td>\n",
       "      <td>4FDA9FBAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef2477eb-67ca-43bf-bab4-826d872d47e7</th>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20236</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:16:00</td>\n",
       "      <td>3650A24CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd74ace6-6582-4e71-ada9-f21760846ade</th>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20233</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:04:00</td>\n",
       "      <td>178964118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c8a7cd74-931c-4b38-814f-779874d69417</th>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20238</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:21:00</td>\n",
       "      <td>3C86CC2F2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95df6a78-d1f0-4c98-b349-96f1e9d6b10c</th>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20231</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>31/07/2023 12:54:00</td>\n",
       "      <td>42BC784C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184149d-ac46-473a-8246-a39b2a9f302d</th>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>PM_MESQUITA</td>\n",
       "      <td>20232</td>\n",
       "      <td>Agosto/2023</td>\n",
       "      <td>01/08/2023 20:00:00</td>\n",
       "      <td>DAD4C3BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b1c342f-8049-410f-957b-fd1bf0ffc8c7</th>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3f115ed4-885f-4d2a-b2d5-c42da4348d42</th>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                              1.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                        2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                        2023 -7.pdf   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                        2023 -4.pdf   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                        2023 -6.pdf   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                        2023 -3.pdf   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                        2023 -8.pdf   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                          31-07.pdf   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     MESQUITA_PDF_31282023_2258.zip   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     Livro de Registro do ISSQN.pdf   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  pdf_pesquisavel     model  \\\n",
       "document_unique_id                                                          \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste              0.0      MAGE   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871              1.0  MESQUITA   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871              1.0  MESQUITA   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    159871              1.0  MESQUITA   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    159871              1.0  MESQUITA   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    159871              1.0  MESQUITA   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    159871              1.0  MESQUITA   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    160014              1.0  MESQUITA   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    160014              1.0  MESQUITA   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir              NaN       NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964              NaN       NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    126623              1.0       NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    138565              1.0       NaN   \n",
       "\n",
       "                                                                tipo_nota_fiscal  \\\n",
       "document_unique_id                                                                 \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                                         NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                                         NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                                         NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                                         NaN   \n",
       "\n",
       "                                                           secretaria  \\\n",
       "document_unique_id                                                      \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  SECRETARIA MUNICIPAL DA FAZENDA   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                              NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                              NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                              NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                              NaN   \n",
       "\n",
       "                                                            prefeitura  \\\n",
       "document_unique_id                                                       \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2      PREFEITURA MUNICIPAL DE MAGE   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                               NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                               NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                               NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                               NaN   \n",
       "\n",
       "                                       de_para_pm numero_nota_fiscal  \\\n",
       "document_unique_id                                                     \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2      PM_MAGE                  1   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  PM_MESQUITA              20235   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  PM_MESQUITA              20237   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  PM_MESQUITA              20234   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  PM_MESQUITA              20236   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  PM_MESQUITA              20233   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  PM_MESQUITA              20238   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  PM_MESQUITA              20231   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  PM_MESQUITA              20232   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357          NaN                NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48          NaN                NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7          NaN                NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42          NaN                NaN   \n",
       "\n",
       "                                      competencia        dt_hr_emissao  \\\n",
       "document_unique_id                                                       \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2   Julho/2023  31/07/2023 17:29:00   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e   Julho/2023  27/07/2023 15:13:00   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48   Julho/2023  27/07/2023 15:19:00   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c   Julho/2023  27/07/2023 15:11:00   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7   Julho/2023  27/07/2023 15:16:00   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade   Julho/2023  27/07/2023 15:04:00   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417   Julho/2023  27/07/2023 15:21:00   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c   Julho/2023  31/07/2023 12:54:00   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  Agosto/2023  01/08/2023 20:00:00   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357          NaN                  NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48          NaN                  NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7          NaN                  NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42          NaN                  NaN   \n",
       "\n",
       "                                     codigo_verificacao  \n",
       "document_unique_id                                       \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2          4ADEE6A7B  \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e          92ED36652  \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48          C45A7FCE4  \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c          4FDA9FBAE  \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7          3650A24CE  \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade          178964118  \n",
       "c8a7cd74-931c-4b38-814f-779874d69417          3C86CC2F2  \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c          42BC784C8  \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d          DAD4C3BCC  \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                NaN  \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                NaN  \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                NaN  \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Conferencia 1\n",
    "df_conf1 = df_result_pipe[['original_file_name', 'directory', 'pdf_pesquisavel','model','tipo_nota_fiscal','secretaria','prefeitura', 'de_para_pm',  'numero_nota_fiscal', 'competencia', 'dt_hr_emissao','codigo_verificacao']]\n",
    "df_conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>pdf_pesquisavel</th>\n",
       "      <th>p_cpf_cnpj_com_mascara</th>\n",
       "      <th>p_cpf_cnpj_sem_mascara</th>\n",
       "      <th>p_telefone</th>\n",
       "      <th>p_inscricao_municipal</th>\n",
       "      <th>p_inscricao_estadual</th>\n",
       "      <th>razao_social_prestador</th>\n",
       "      <th>p_nome_fantasia</th>\n",
       "      <th>endereco_prestador</th>\n",
       "      <th>p_email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.246.375/0001-77</td>\n",
       "      <td>51246375000177</td>\n",
       "      <td></td>\n",
       "      <td>1007689</td>\n",
       "      <td>2176361620..</td>\n",
       "      <td>BOM GOSTO TRANSPORTES E SERVICOS</td>\n",
       "      <td>BOM GOSTO TRANSPORTES</td>\n",
       "      <td>VINTE E CINCO ,115,PARQUE SAYONARA</td>\n",
       "      <td>FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.921.369/0001-05</td>\n",
       "      <td>50921369000105</td>\n",
       "      <td>2297268232..</td>\n",
       "      <td>952538</td>\n",
       "      <td></td>\n",
       "      <td>MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...</td>\n",
       "      <td></td>\n",
       "      <td>RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...</td>\n",
       "      <td>LARA_VSORIA@HOTMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.921.369/0001-05</td>\n",
       "      <td>50921369000105</td>\n",
       "      <td>2297268232..</td>\n",
       "      <td>952538</td>\n",
       "      <td></td>\n",
       "      <td>MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...</td>\n",
       "      <td></td>\n",
       "      <td>RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...</td>\n",
       "      <td>LARA_VSORIA@HOTMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c</th>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.921.369/0001-05</td>\n",
       "      <td>50921369000105</td>\n",
       "      <td>2297268232..</td>\n",
       "      <td>952538</td>\n",
       "      <td></td>\n",
       "      <td>MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...</td>\n",
       "      <td></td>\n",
       "      <td>RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...</td>\n",
       "      <td>LARA_VSORIA@HOTMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef2477eb-67ca-43bf-bab4-826d872d47e7</th>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.921.369/0001-05</td>\n",
       "      <td>50921369000105</td>\n",
       "      <td>2297268232..</td>\n",
       "      <td>952538</td>\n",
       "      <td></td>\n",
       "      <td>MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...</td>\n",
       "      <td></td>\n",
       "      <td>RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...</td>\n",
       "      <td>LARA_VSORIA@HOTMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd74ace6-6582-4e71-ada9-f21760846ade</th>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.921.369/0001-05</td>\n",
       "      <td>50921369000105</td>\n",
       "      <td>2297268232..</td>\n",
       "      <td>952538</td>\n",
       "      <td></td>\n",
       "      <td>MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...</td>\n",
       "      <td></td>\n",
       "      <td>RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...</td>\n",
       "      <td>LARA_VSORIA@HOTMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c8a7cd74-931c-4b38-814f-779874d69417</th>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.921.369/0001-05</td>\n",
       "      <td>50921369000105</td>\n",
       "      <td>2297268232..</td>\n",
       "      <td>952538</td>\n",
       "      <td></td>\n",
       "      <td>MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...</td>\n",
       "      <td></td>\n",
       "      <td>RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...</td>\n",
       "      <td>LARA_VSORIA@HOTMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95df6a78-d1f0-4c98-b349-96f1e9d6b10c</th>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.156.898/0001-22</td>\n",
       "      <td>51156898000122</td>\n",
       "      <td>21995883745.</td>\n",
       "      <td>952681</td>\n",
       "      <td></td>\n",
       "      <td>51.156.898 EDVALDO DA COSTA NASCIMENTO</td>\n",
       "      <td></td>\n",
       "      <td>RUA LIBANIA I ,112 ,VILA EMIL - Mesquita-RJ</td>\n",
       "      <td>THALIITA.TCN@GMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184149d-ac46-473a-8246-a39b2a9f302d</th>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.156.898/0001-22</td>\n",
       "      <td>51156898000122</td>\n",
       "      <td>21995883745.</td>\n",
       "      <td>952681</td>\n",
       "      <td></td>\n",
       "      <td>51.156.898 EDVALDO DA COSTA NASCIMENTO</td>\n",
       "      <td></td>\n",
       "      <td>RUA LIBANIA I ,112 ,VILA EMIL - Mesquita-RJ</td>\n",
       "      <td>THALIITA.TCN@GMAIL.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b1c342f-8049-410f-957b-fd1bf0ffc8c7</th>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3f115ed4-885f-4d2a-b2d5-c42da4348d42</th>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                              1.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                        2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                        2023 -7.pdf   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                        2023 -4.pdf   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                        2023 -6.pdf   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                        2023 -3.pdf   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                        2023 -8.pdf   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                          31-07.pdf   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     MESQUITA_PDF_31282023_2258.zip   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     Livro de Registro do ISSQN.pdf   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  pdf_pesquisavel  \\\n",
       "document_unique_id                                                \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste              0.0   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871              1.0   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871              1.0   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    159871              1.0   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    159871              1.0   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    159871              1.0   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    159871              1.0   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    160014              1.0   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    160014              1.0   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir              NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964              NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    126623              1.0   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    138565              1.0   \n",
       "\n",
       "                                     p_cpf_cnpj_com_mascara  \\\n",
       "document_unique_id                                            \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     51.246.375/0001-77   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e     50.921.369/0001-05   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48     50.921.369/0001-05   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c     50.921.369/0001-05   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7     50.921.369/0001-05   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade     50.921.369/0001-05   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417     50.921.369/0001-05   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c     51.156.898/0001-22   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d     51.156.898/0001-22   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                    NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                    NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                    NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                    NaN   \n",
       "\n",
       "                                     p_cpf_cnpj_sem_mascara    p_telefone  \\\n",
       "document_unique_id                                                          \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2         51246375000177                 \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e         50921369000105  2297268232..   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48         50921369000105  2297268232..   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c         50921369000105  2297268232..   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7         50921369000105  2297268232..   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade         50921369000105  2297268232..   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417         50921369000105  2297268232..   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c         51156898000122  21995883745.   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d         51156898000122  21995883745.   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                    NaN           NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                    NaN           NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                    NaN           NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                    NaN           NaN   \n",
       "\n",
       "                                     p_inscricao_municipal  \\\n",
       "document_unique_id                                           \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2               1007689   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                952538   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                952538   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                952538   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                952538   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                952538   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                952538   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                952681   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d                952681   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                   NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                   NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                   NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                   NaN   \n",
       "\n",
       "                                     p_inscricao_estadual  \\\n",
       "document_unique_id                                          \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2         2176361620..   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                        \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                        \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                        \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                        \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                        \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                        \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                        \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                  NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                  NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                  NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                  NaN   \n",
       "\n",
       "                                                                 razao_social_prestador  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                   BOM GOSTO TRANSPORTES E SERVICOS   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLO...   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c             51.156.898 EDVALDO DA COSTA NASCIMENTO   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d             51.156.898 EDVALDO DA COSTA NASCIMENTO   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                                                NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                                                NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                                                NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                                                NaN   \n",
       "\n",
       "                                            p_nome_fantasia  \\\n",
       "document_unique_id                                            \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  BOM GOSTO TRANSPORTES   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                          \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                          \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                          \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                          \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                          \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                          \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                          \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d                          \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                    NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                    NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                    NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                    NaN   \n",
       "\n",
       "                                                                     endereco_prestador  \\\n",
       "document_unique_id                                                                        \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                 VINTE E CINCO ,115,PARQUE SAYONARA   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesqui...   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c        RUA LIBANIA I ,112 ,VILA EMIL - Mesquita-RJ   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d        RUA LIBANIA I ,112 ,VILA EMIL - Mesquita-RJ   \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                                                NaN   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                                                NaN   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                                                NaN   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                                                NaN   \n",
       "\n",
       "                                                                                p_email  \n",
       "document_unique_id                                                                       \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INH...  \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                            LARA_VSORIA@HOTMAIL.COM  \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                            LARA_VSORIA@HOTMAIL.COM  \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                            LARA_VSORIA@HOTMAIL.COM  \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                            LARA_VSORIA@HOTMAIL.COM  \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                            LARA_VSORIA@HOTMAIL.COM  \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                            LARA_VSORIA@HOTMAIL.COM  \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                             THALIITA.TCN@GMAIL.COM  \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d                             THALIITA.TCN@GMAIL.COM  \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                                                NaN  \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                                                NaN  \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7                                                NaN  \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42                                                NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Conferencia 2\n",
    "df_conf2 = df_result_pipe[['original_file_name', 'directory', 'pdf_pesquisavel','p_cpf_cnpj_com_mascara', 'p_cpf_cnpj_sem_mascara', 'p_telefone', 'p_inscricao_municipal', 'p_inscricao_estadual', 'razao_social_prestador', 'p_nome_fantasia', 'endereco_prestador', 'p_email']]\n",
    "df_conf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Conferencia 3\n",
    "df_conf3 = df_result_pipe[['original_file_name', 'directory', 'pdf_pesquisavel','t_cpf_cnpj_com_mascara', 't_cpf_cnpj_sem_mascara', 't_inscricao_municipal', 't_telefone', 't_RG', 't_inscricao_estadual', 't_nome_razao_social', 't_endereco', 't_email']]\n",
    "df_conf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Conferencia 4\n",
    "df_conf4 = df_result_pipe[['original_file_name', 'directory', 'pdf_pesquisavel','discriminacao_servicos', 'valor_total_nota', 'cnae','item_lista_servicos']]\n",
    "df_conf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Conferencia 5\n",
    "df_conf5 = df_result_pipe[['original_file_name', 'directory', 'pdf_pesquisavel','valor_servicos', 'valor_deducao', 'desc_incond', 'base_calculo','aliquota', 'valor_iss', 'valor_iss_retido', 'desc_cond', 'valor_pis', 'valor_cofins', 'valor_ir', 'valor_inss', 'valor_csll','outras_retencoes', 'valor_liquido']]\n",
    "df_conf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Conferencia 6\n",
    "df_conf6 = df_result_pipe[['original_file_name', 'directory', 'pdf_pesquisavel','dados_complementares','exigibilidade_iss', 'regime_tributacao', 'simples_nacional', 'issqn_retido', 'local_prestacao_servico', 'local_incidencia', 'observacao']]\n",
    "df_conf6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. XXX Definiçao do path para salvar o arquivo\n",
    "file_path_df_result_pipe = os.path.join(map_analise_path, 'df_result_pipe_' + batch_name + \".xlsx\")\n",
    "\n",
    "# 2. XXX Salvando o arquivo de df: df_result_pipe\n",
    "df_result_pipe.to_excel(file_path_df_result_pipe, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>2.4</b> Exportacao json </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 XXX. Leio a planilha de conferencia avalidada\n",
    "file_path_df_result_pipe = os.path.join(map_analise_path, 'df_result_pipe_' + batch_name + \".xlsx\")\n",
    "\n",
    "\n",
    "#Le a planilha e cria do DF\n",
    "df_validated_pipe = pd.read_excel(file_path_df_result_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Crio subset somente dos documentos para exportar\n",
    "df_conf_validada = utl.filtrar_df(df_validated_pipe, action_item=\"EXPORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Ajusto o Index\n",
    "df_conf_validada.set_index('document_unique_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dados para formataÇao do Json\n",
    "de_para_pm = df_conf_validada['de_para_pm'].values[0]\n",
    "municipio = df_conf_validada['municipio'].values[0]\n",
    "arquivo_zip = df_conf_validada['parent_file'].values[0]\n",
    "data_processamento = cron.timenow_pt_BR()\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "titulo = (f'Processamento {batch_name} - {de_para_pm} - data:{data_processamento}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Crio o JSON \n",
    "dados_json = {}\n",
    "\n",
    "# Iterar sobre cada linha no DataFrame\n",
    "for index, row in df_conf_validada.iterrows():\n",
    "    # dados_df e o dicionario para armazenar os dados da nota fiscal atual\n",
    "    #diretorio = str(row['directory'])\n",
    "    dados_nf = {\n",
    "            \"dados_NF_PDF\": {\n",
    "                                \"data_cabecalho\": {\n",
    "                                    \"secao\": \"1 - CABECALHO\",\n",
    "                                    \"nome_prefeitura\": row['prefeitura'],\n",
    "                                    \"numero_nota_fiscal\": row['numero_nota_fiscal'],\n",
    "                                    \"competencia\": row['competencia'],\n",
    "                                    \"dt_hr_emissoa\": row['dt_hr_emissao'],\n",
    "                                    \"codigo_verificacao\": row['codigo_verificacao']\n",
    "                                },\n",
    "                                \"data_prestador\": {\n",
    "                                    \"secao\": \"2. PRESTADOR DE SERVIÇO\",\n",
    "                                    \"cpf_cnpj_com_mascara\": row['p_cpf_cnpj_com_mascara'],\n",
    "                                    \"cpf_cnpj_sem_mascara\": row['p_cpf_cnpj_sem_mascara'],\n",
    "                                    \"inscricao_municipal\": row['p_inscricao_municipal'],\n",
    "                                    \"inscricao_estadual\": row['p_inscricao_estadual'],\n",
    "                                    \"telefone\": row['p_telefone'],\n",
    "                                    \"razao_social\": row['razao_social_prestador'],\n",
    "                                    \"nome_fantasia\": row['p_nome_fantasia'],\n",
    "                                    \"endereco\": row['endereco_prestador'],\n",
    "                                    \"email\": row['p_email']\n",
    "                                },\n",
    "                                \"data_tomador\": {\n",
    "                                    \"secao\": \"3. TOMADOR DE SERVIÇO\",\n",
    "                                    \"cpf_cnpj_com_mascara\": row['t_cpf_cnpj_com_mascara'],\n",
    "                                    \"cpf_cnpj_sem_mascara\": row['t_cpf_cnpj_sem_mascara'],\n",
    "                                    \"rg\": row['t_RG'],\n",
    "                                    \"inscricao_municipal\": row['t_inscricao_municipal'],\n",
    "                                    \"inscricao_estadual\": row['t_inscricao_estadual'],\n",
    "                                    \"telefone\": row['t_telefone'],\n",
    "                                    \"razao_social\": row['t_nome_razao_social'],\n",
    "                                    \"endereco\": row['t_endereco'],\n",
    "                                    \"email\": row['t_email']\n",
    "                                },\n",
    "                                \"data_servico\": {\n",
    "                                    \"secao\": \"4. DESCRIMINACAO DOS SERVIÇOS\",\n",
    "                                    \"discriminacao_servicos\": row['discriminacao_servicos']\n",
    "                                },\n",
    "                                \"data_valor_total\": {\n",
    "                                    \"secao\": \"5. VALOR TOTAL\",\n",
    "                                    \"valor_total_nota\": row['valor_total_nota']\n",
    "                                },\n",
    "                                \"data_CNAE\": {\n",
    "                                    \"secao\": \"6. CNAE e Item da Lista de Serviços\",\n",
    "                                    \"cnae\": row['cnae'],\n",
    "                                    \"item_lista_servicos\": row['item_lista_servicos']\n",
    "                                },\n",
    "                                \"data_valores\": {\n",
    "                                    \"secao\": \"7. VALORES E IMPOSTOS\",\n",
    "                                    \"valor_servicos\": row['valor_servicos'],\n",
    "                                    \"valor_deducao\": row['valor_deducao'],\n",
    "                                    \"desc_incond\" : row['desc_incond'],\n",
    "                                    \"base_calculo\": row['base_calculo'],\n",
    "                                    \"aliquota\": row['aliquota'],\n",
    "                                    \"valor_iss\": row['valor_iss'],\n",
    "                                    \"valor_iss_retido\": row['valor_iss_retido'],\n",
    "                                    \"desc_cond\": row['desc_cond'],\n",
    "                                    \"valor_pis\": row['valor_pis'],\n",
    "                                    \"valor_cofins\": row['valor_cofins'],\n",
    "                                    \"valor_ir\": row['valor_ir'],\n",
    "                                    \"valor_inss\": row['valor_inss'],\n",
    "                                    \"valor_csll\": row['valor_csll'],\n",
    "                                    \"outras_retencoes\": row['outras_retencoes'],\n",
    "                                    \"valor_liquido\": row['valor_liquido']\n",
    "                                },\n",
    "                                \"data_dados_complementares\": {\n",
    "                                    \"secao\": \"8. DADOS COMPLEMENTARES\",\n",
    "                                    \"dados_complementares\": row['dados_complementares']\n",
    "                                },\n",
    "                                \"data_outras_informacoes\": {\n",
    "                                    \"secao\": \"9. OUTRAS INFORMAÇOES / CRITICAS\",\n",
    "                                    \"exigibilidade_iss\": row['exigibilidade_iss'],\n",
    "                                    \"regime_tributacao\": row['regime_tributacao'],\n",
    "                                    \"simples_nacional\": row['simples_nacional'],\n",
    "                                    \"issqn_retido\": row['issqn_retido'],\n",
    "                                    \"local_prestacao_servico\": row['local_prestacao_servico'],\n",
    "                                    \"local_incidencia\": row['local_incidencia']\n",
    "                                },\n",
    "                                \"data_observacao\": {\n",
    "                                    \"secao\": \"10. OBSERVACOES\",\n",
    "                                    \"observacao\": row['observacao']\n",
    "                                },\n",
    "                            },\n",
    "                            \"batch\": row['batch'],    \n",
    "                            \"diretorio\": str(row['directory']),\n",
    "                            \"nome_arquivo\": row['original_file_name'],\n",
    "                            \"pdf_pesquisavel\": row['pdf_pesquisavel'],\n",
    "                            \"modelo\": row['model'],   \n",
    "                            \"document_unique_id\": index,\n",
    "                            \"parent_file\": row['parent_file'],\n",
    "                    }        \n",
    "            \n",
    "    \n",
    "    numero_nota_fiscal = str(row['numero_nota_fiscal'])\n",
    "    dados_json['titulo'] = titulo\n",
    "    dados_json['batch'] = batch_name\n",
    "    dados_json['municipio'] = municipio\n",
    "    # dados_json['data_processamento'] = cron.timenow_pt_BR()\n",
    "    dados_json[numero_nota_fiscal] = dados_nf\n",
    "\n",
    "# Salvando em formato JSON\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(dados_json, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "print(f\"As informações foram salvas em {json_file_path}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. XXX Definiçao do path para salvar o arquivo\n",
    "file_path_df_conf_export = os.path.join(map_analise_path, 'df_conf_export_' + batch_name + \".xlsx\")\n",
    "\n",
    "# 2. XXX Salvando o arquivo de df: df_result_pipe\n",
    "df_validated_pipe.to_excel(file_path_df_conf_export, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>2.5</b> Analise do template (model) </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. XXX Processo para analisar template executado no Batch para o item\n",
    "\n",
    "file_name = \"2023 -3.pdf\"\n",
    "dw_types = ['boundaries', 'frame', 'field_box']\n",
    "\n",
    "\n",
    "analisar_model_np(file_name, dw_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = '27df9e70-b5fb-45b7-8f59-0c04ed9728e2'\n",
    "sample_text = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"1.pdf\"\n",
    "\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_cabecalho\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['boundaries', 'frame', 'field_box', 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_model_np(file_name, debug=False):\n",
    "    \n",
    "    doc_analise = utl.filtrar_df(df_result_pipe, original_file_name=file_name) \n",
    "    pdf_pesquisavel_map = doc_analise['pdf_pesquisavel'].values[0]\n",
    "    model = doc_analise['model'].values[0]\n",
    "    original_file_name = doc_analise['original_file_name'].values[0]\n",
    "    de_para_pm = doc_analise['de_para_pm'].values[0]\n",
    "\n",
    "\n",
    "    original_file_name = doc_analise['original_file_name'].values[0] \n",
    "    file_path = doc_analise['file_path'].values[0] \n",
    "    imagem_gray, image_resized_name = convert_resize_gray(original_file_name, file_path, image_resized_path) \n",
    "\n",
    "        \n",
    "    image = Image.open(image_resized_name).convert(\"RGB\")\n",
    "    # Converta a imagem para um array NumPy\n",
    "    image_np = np.array(image)\n",
    "    os.remove(image_resized_name)\n",
    "    \n",
    "    draw_boxes(image_np, frames_nf_v4_df, model, draw_types=dw_types)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(image_np, frames_nf_v4_df, 'SPA', draw_types=['boundaries', 'field_box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_model_np(file_name, debug=False):\n",
    "    \n",
    "    doc_analise = utl.filtrar_df(df_result_pipe, original_file_name=file_name) \n",
    "    pdf_pesquisavel_map = doc_analise['pdf_pesquisavel'].values[0]\n",
    "    model = doc_analise['model'].values[0]\n",
    "    original_file_name = doc_analise['original_file_name'].values[0]\n",
    "    de_para_pm = doc_analise['de_para_pm'].values[0]\n",
    "\n",
    "\n",
    "    original_file_name = doc_analise['original_file_name'].values[0] \n",
    "    file_path = doc_analise['file_path'].values[0] \n",
    "    imagem_gray, image_resized_name = convert_resize_gray(original_file_name, file_path, image_resized_path) \n",
    "\n",
    "        \n",
    "    image = Image.open(image_resized_name).convert(\"RGB\")\n",
    "    # Converta a imagem para um array NumPy\n",
    "    image_np = np.array(image)\n",
    "    os.remove(image_resized_name)\n",
    "    \n",
    "    draw_boxes(image_np, frames_nf_v4_df, model, draw_types=dw_types)     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "color_mapping = {\n",
    "    \"red\": (1, 0, 0),\n",
    "    \"purple\": (0.5, 0, 0.5),\n",
    "    \"orange\": (1, 0.647, 0),\n",
    "    \"green\": (0, 0.5, 0.196),\n",
    "    \"blue\": (0, 0, 1),\n",
    "    \"yellow\": (1, 1, 0),\n",
    "}\n",
    "\n",
    "\n",
    "def draw_boxes(image_np, df, modelo, draw_types=None):\n",
    "    plt.figure(figsize=(25, 25))\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Filtrar baseado no modelo e nos tipos de \"boxes\" a serem desenhados\n",
    "    filtered_df = df[df['model'] == modelo]\n",
    "    if draw_types:\n",
    "        filtered_df = filtered_df[filtered_df['type'].isin(draw_types)]\n",
    "    \n",
    "    for index, row in filtered_df.iterrows():\n",
    "        x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        \n",
    "        color = color_mapping.get(row['color'], 'black')\n",
    "        \n",
    "        # Adicionando o retângulo\n",
    "        plt.gca().add_patch(Rectangle((x0, y0), x1-x0, y1-y0, linewidth=1, edgecolor=color, facecolor='none'))\n",
    "        \n",
    "        # Adicionando o rótulo, se existir\n",
    "        label = str(row['label']) if pd.notnull(row['label']) else None\n",
    "        if label:\n",
    "            plt.text(x0 + 10, y0 - 15, label, color=color, fontsize=10)\n",
    "            plt.text(x0 + 20, y0 + 55,(x0, y0, x1, y1), color='black', fontsize=7)\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de apresentaçao da imagem\n",
    "x0 = 0\n",
    "y0 = 0\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.imshow(imagem_gray_np)\n",
    "plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "plt.text(x0 + 1, y0 + 10,original_file_name, color='black', fontsize=20)\n",
    "#plt.text(original_file_name, color='black', fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mapping_method == \"frame_&_sframe_field\":\n",
    "    tipo_4_coordinates = \"frame\"\n",
    "    tipo_4_filter = \"sframe_field\"\n",
    "coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model, context_mapping, tipo_4_coordinates)\n",
    "x0, y0, x1, y1 = coordinates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Determine as colunas de coordenadas a serem usadas\n",
    "    x0_col, y0_col, x1_col, y1_col = ('x0_p', 'y0_p', 'x1_p', 'y1_p') if is_searchable else ('x0', 'y0', 'x1', 'y1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_file_name = \"Doria Marinho 0297 Raquel.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de apresentaçao da imagem\n",
    "x0 = 0\n",
    "y0 = 0\n",
    "plt.figure(figsize=(25, 25))\n",
    "plt.imshow(result['image_np'].values[0])\n",
    "plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "plt.text(x0 + 1, y0 + 10,original_file_name, color='black', fontsize=20)\n",
    "#plt.text(original_file_name, color='black', fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_np = result['image_np'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = int(x0)\n",
    "y0 = int(y0)\n",
    "x1 = int(x1)    \n",
    "y1 = int(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_np = imagem_gray_np[y0:y1, x0:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de apresentaçao da imagem\n",
    "x0 = 0\n",
    "y0 = 0\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(cropped_image_np)\n",
    "plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "#plt.text(x0 + 1, y0 + 10,original_file_name, color='black', fontsize=20)\n",
    "#plt.text(original_file_name, color='black', fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_info = {}\n",
    "i = 1\n",
    "for idx, row in boxes.iterrows():\n",
    "    x0 = int(row['x0'])\n",
    "    y0 = int(row['y0'])\n",
    "    x1 = int(row['x1'])\n",
    "    y1 = int(row['y1'])\n",
    "    cropped_image_np = imagem_gray_np[y0:y1, x0:x1]\n",
    "    \n",
    "    boxes_info[f'box_{i}'] = {\n",
    "        'coordinates': (x0, y0, x1, y1),\n",
    "        'image': cropped_image_np,\n",
    "        # ... qualquer outra informação que você deseja armazenar\n",
    "    }\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_info['box_1']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_info['box_1']['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box in boxes_info:\n",
    "    x0, y0, x1, y1 = boxes_info[box]['coordinates']\n",
    "    image = boxes_info[box]['image']\n",
    "    # plt.figure(figsize=(25, 25))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "\n",
    "x0 = 0\n",
    "y0 = 0\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(boxes_info[f'box_{i}']['image'])\n",
    "plt.text(x0 , y0,boxes_info[f'box_{i}']['coordinates'], color='green', fontsize=7)\n",
    "plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialize um dicionário vazio para armazenar as informações dos \"boxes\"\n",
    "boxes_info = {}\n",
    "\n",
    "# Suponha que você está em um loop onde está processando vários \"boxes\"\n",
    "for i, box in enumerate(boxes):\n",
    "    # Obtenha as coordenadas do \"box\"\n",
    "    x0, y0, x1, y1 = coordinates[0] \n",
    "    # Corte a área do \"box\" da imagem original\n",
    "    cropped_image = imagem_gray_np[y0:y1, x0:x1]\n",
    "    \n",
    "    # Armazene as informações do \"box\" no dicionário\n",
    "    boxes_info[f'box_{i}'] = {\n",
    "        'coordinates': (x0, y0, x1, y1),\n",
    "        'image': cropped_image,\n",
    "        # ... qualquer outra informação que você deseja armazenar\n",
    "    }\n",
    "\n",
    "# Agora, `boxes_info` contém informações detalhadas sobre cada \"box\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Variáveis para armazenar as coordenadas do retângulo\n",
    "startX, startY, endX, endY = -1, -1, -1, -1\n",
    "drawing = False\n",
    "\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global startX, startY, endX, endY, drawing\n",
    "\n",
    "    # Se o botão esquerdo do mouse for pressionado, comece a desenhar o retângulo\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        startX, startY = x, y\n",
    "\n",
    "    # Se o botão esquerdo do mouse for solto, finalize o retângulo\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        endX, endY = x, y\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "# Carregue sua imagem como um array NumPy\n",
    "img = np.copy(image_np) # Substitua 'image_np' pelo seu array NumPy da imagem\n",
    "\n",
    "# Crie uma janela e atribua a função de callback\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", draw_rectangle)\n",
    "\n",
    "while True:\n",
    "    # Exibe a imagem\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    # Se a tecla 'q' for pressionada, saia do loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Fecha todas as janelas OpenCV\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Criar um dicionário para matchers patterns - nfs-e\n",
    "# Criar nova rotina de salvamento de dicionário de matchers patterns\n",
    "\n",
    "\n",
    "matcher_pattern_dict = [\n",
    "                            {\n",
    "                                \"label\": \"endereco_site\",\n",
    "                                \"pattern\": [\n",
    "                                        {\"SHAPE\": \"xxxx://xxx.xxxx.xx.xxx.xx\"}\n",
    "                                ]         \n",
    "                            },\n",
    "                            {\n",
    "                                \"label\": \"OUTRO_LABEL\",\n",
    "                                \"pattern\": [\n",
    "                                        {\"LOWER\": \"valor\"},\n",
    "                                        {\"LOWER\": \"líquido\"},\n",
    "                                        {\"ORTH\": \":\"},\n",
    "                                        {\"SHAPE\": \"X$\"},\n",
    "                                        {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "                                        {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "                                        {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "                                ]\n",
    "                            }\n",
    "                        \n",
    "                        ]\n",
    "\n",
    "# Salvando com indentações\n",
    "with open(\"dados_formatados.json\", \"w\") as f:\n",
    "    json.dump(matcher_pattern_dict, f, indent=4)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Carregar o JSON dos padrões\n",
    "with open(\"dados_formatados.json\", \"r\") as f:\n",
    "    loaded_patterns = json.load(f)\n",
    "\n",
    "# Adicionar os padrões ao Matcher\n",
    "for item in loaded_patterns:\n",
    "    label = item[\"label\"]\n",
    "    pattern = item[\"pattern\"]\n",
    "    matcher.add(label, [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_validada['de_para_pm'].values[0]\n",
    "df_conf_validada['municipio'].values[0]\n",
    "df_conf_validada['parent_file'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coluna_cnae'] = df['coluna_cnae'].apply(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_avalida_batch_21['numero_nota_fiscal'] = df_conf_avalida_batch_21['numero_nota_fiscal'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustes Matchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX 1.Processar todas as secoes do documento\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=True, tomador=True, servicos=True, total=True, cnae=True, valores_impostos=True, complementares=True, outras_informacoes=True, observacoes=True)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Processar valor Total\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=True, cnae=False, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 6. Processar CNAE\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=True, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 7. Processar Impostos\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 8. complementar e observaçoes\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=False, complementares=True, outras_informacoes=True, observacoes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id:>30} | {span.text:>50} | {span.start_char:>5}  {span.end_char:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_pipe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = \"ab2457b7-ea5c-4191-acf0-bc8edc04879e\"\n",
    "file_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento/Batch_23/MESQUITA_PDF_31282023_2258/teste/1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "servicos_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "valor_total_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '5. VALOR TOTAL'][0]\n",
    "bloco_discriminacao_servico = texto[servicos_end_char:valor_total_start_char]\n",
    "bloco_discriminacao_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = 'ab2457b7-ea5c-4191-acf0-bc8edc04879e'\n",
    "texto = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "doc = nlp(texto)\n",
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "outras_informacoes_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '9. OUTRAS INFORMAÇOES / CRITICAS'][0]\n",
    "observacoes_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '10. OBSERVACOES'][0]\n",
    "text = texto[outras_informacoes_end_char:observacoes_start_char]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    #nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outras_ref = ['EXIGIBILIDADE ISS', 'REGIME TRIBUTAÇÃO', 'SIMPLES NACIONAL', 'ISSQN RETIDO', 'LOCAL. PRESTAÇÃO SERVIÇO', 'LOCAL INCIDÊNCIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_texto = \"EXIGIBILIDADE ISS\\nExigivel\\nREGIME TRIBUTAÇÃO\\nSociedade Limitada\\nSIMPLES NACIONAL\\nSim (2,01% )\\nISSQN RETIDO\\nNão\\nLOCAL. PRESTAÇÃO SERVIÇO\\nMagé - RJ\\nLOCAL INCIDÊNCIA\\nMagé - RJ\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outras_informacoes = {}\n",
    "data_outras_informacoes = novaextra.extract_fields_outras_info(novo_texto)\n",
    "data_outras_informacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outras_informacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. OBSERVACOES\n",
    "observacoes_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '10. OBSERVACOES'][0]\n",
    "encerrador_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'encerrador'][0]\n",
    "bloco_observacoes = texto[observacoes_end_char:encerrador_start_char]\n",
    "bloco_observacoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posições de início e fim\n",
    "start_pos = 881\n",
    "end_pos = 1520\n",
    "\n",
    "# Extraindo a sub-string usando slicing\n",
    "extracted_text = texto[start_pos:end_pos]\n",
    "\n",
    "print(f\"Texto extraído: {extracted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloco_discriminacao_servico = original_text[servicos_end_char:valor_total_start_char]\n",
    "bloco_discriminacao_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servicos_end = [ent.end for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "servicos_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_total_start = [ent.start for ent in doc.ents if ent.id_ == '5. VALOR TOTAL'][0]\n",
    "valor_total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloco_discriminacao_servico = texto[servicos_end:valor_total_start]\n",
    "bloco_discriminacao_servico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte do mapeamento do cabeÇalho para Raster_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = 'ab2457b7-ea5c-4191-acf0-bc8edc04879e'\n",
    "texto_R_PDF = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "texto_R_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_R_PDF = Novo_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_R_PDF, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = {}\n",
    "section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_prestador\"\n",
    "model_map = \"MESQUITA\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando a razao social - Prestador\n",
    "label = \"p_razao_social\"\n",
    "end_chars_razao_prestado = [token.idx + len(token) for token in doc if token.ent_id_ == label][4]\n",
    "end_chars_razao_prestado = end_chars_razao_prestado + 1\n",
    "label = \"p_nome_fantasia\"\n",
    "star_chars_fantasia = [token.idx for token in doc if token.ent_id_ == label][0]\n",
    "star_chars_fantasia = star_chars_fantasia - 1\n",
    "razao_social_texto = texto_R_PDF[end_chars_razao_prestado:star_chars_fantasia]\n",
    "razao_social_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ini_char = min(end_chars)\n",
    "end_char = max(end_chars)\n",
    "\n",
    "fatiado = doc.text[ini_char:end_char]\n",
    "\n",
    "print(f'ini_char: {ini_char} | end_char: {end_char} | fatiado: {fatiado} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_box_valores = {}\n",
    "if mapping_method == \"frame_&_sframe_field\":\n",
    "    tipo_4_coordinates = \"frame\"\n",
    "    tipo_4_filter = \"sframe_field\"\n",
    "\n",
    "# 8. Efetuo o filtro para a iteracao\n",
    "filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "# 9. iter sobre o filtro\n",
    "for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "    section = row_frame['section_json']\n",
    "    label = row_frame['label']\n",
    "    reference = row_frame['reference']\n",
    "    string_pesquisa = row_frame['marcador_inicio'] \n",
    "    # last_token_end = 0\n",
    "    if label == \"p_inscricao_municipal\":\n",
    "        last_token_end = 48\n",
    "        new_token_start = 160\n",
    "        print(f'label: {label}\\n')\n",
    "        \n",
    "        end_chars = [token.idx + len(token) for token in doc if token.ent_id_ == label]\n",
    "        ini_char = min(end_chars)\n",
    "        end_char = max(end_chars)\n",
    "        \n",
    "        fatiado = doc.text[ini_char:end_char]\n",
    "        \n",
    "        print(f'ini_char: {ini_char} | end_char: {end_char} | fatiado: {fatiado} \\n')\n",
    "        \n",
    "        syntatic = pd.DataFrame(data=[], \\\n",
    "        columns=[\"id\", \"T_texto\", \"T_idx\", \"T_start_char\", \"T_end_char\", \"T_shape\", \"T_ent_id_\", \"T_ent_type_\"])\n",
    "        \n",
    "        i = 0\n",
    "        for token in doc[last_token_end:new_token_start]:\n",
    "            \n",
    "            start_char = token.idx\n",
    "            end_char = start_char + len(token)\n",
    "            syntatic.loc[i,\"id\"] = token.i\n",
    "            syntatic.loc[i,\"T_texto\"] = token.text\n",
    "            syntatic.loc[i,\"T_idx\"] = token.idx\n",
    "            syntatic.loc[i,\"T_start_char\"] = start_char \n",
    "            syntatic.loc[i,\"T_end_char\"] = end_char\n",
    "            syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "            syntatic.loc[i,\"T_ent_id_\"] = token.ent_id_\n",
    "            syntatic.loc[i,\"T_ent_type_\"] = token.ent_type_\n",
    "            token_end_char = end_char\n",
    "\n",
    "\n",
    "            i = i+1\n",
    "        last_token_end = ent.end_char    \n",
    "\n",
    "syntatic.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"1. CABECALHO\"\n",
    "valores = {}\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_cabecalho\"\n",
    "def_replace = True\n",
    "model_map = \"MAGE\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'numero_nota'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "raw_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomposicao do documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_box_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_cabechalho_PDF_Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_c = nlp(texto_cabechalho_PDF_Raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = '27df9e70-b5fb-45b7-8f59-0c04ed9728e2'\n",
    "texto_R_PDF = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "texto_R_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = 'ab2457b7-ea5c-4191-acf0-bc8edc04879e'\n",
    "texto_PDF_P = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "texto_PDF_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_PDF_P, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc_c)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.start:>5} | {ent.text:>50} | {ent.label_:>25} | {ent.id_:>35}  |   {ent.end:>4}   ||   {ent.start_char:>6} | {ent.end_char:>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu texto OCR completo\n",
    "original_text = texto_R_PDF\n",
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(original_text, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(recomposed_text, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.start:>5} | {ent.text:>50} | {ent.label_:>25} | {ent.id_:>35}  |   {ent.end:>4}   ||   {ent.start_char:>6} | {ent.end_char:>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texto_amostra = \"NFS-e Número da Nota: 20234 Competência: Julho/2023\"\n",
    "texto_amostra = \"'outras informações / criticas'\"\n",
    "\n",
    "doc = nlp(texto_amostra)\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "\n",
    "clean_text = text.replace(': ', ':').replace(', ', ',')\n",
    "\n",
    "clean_text = re.sub('\\s+', ' ', text.replace(': ', ':').replace(', ', ',')).strip()\n",
    "\n",
    "text_splited = texto.split('\\n')\n",
    "text_splited = [x for x in text_splited if x.strip()]\n",
    "text_splited = [s.replace(\";\", \"\").strip() for s in text_splited]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

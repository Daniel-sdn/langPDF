{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kor style schema\n",
    "\n",
    "This is a half-baked prototype that ‚Äúhelps‚Äù you extract structured data from text using LLMs üß©.\n",
    "\n",
    "Specify the schema of what should be extracted and provide some examples.\n",
    "\n",
    "Kor will generate a prompt, send it to the specified LLM and parse out the output.\n",
    "\n",
    "You might even get results back.\n",
    "\n",
    "So yes ‚Äì it‚Äôs just another wrapper on top of LLMs with its own flavor of abstractions. üò∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from kor import create_extraction_chain, Object, Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! frequency_penalty is not default parameter.\n",
      "                    frequency_penalty was transferred to model_kwargs.\n",
      "                    Please confirm that frequency_penalty is what you intended.\n",
      "WARNING! presence_penalty is not default parameter.\n",
      "                    presence_penalty was transferred to model_kwargs.\n",
      "                    Please confirm that presence_penalty is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    top_p=1.0,\n",
    ")\n",
    "\n",
    "schema = Object(\n",
    "    id=\"player\",\n",
    "    description=(\n",
    "        \"O usu√°rio est√° controlando um reprodutor de m√∫sica para selecionar m√∫sicas, paus√°-las, inici√°-las ou reproduzi-las\"\n",
    "        \"m√∫sica de um determinado artista.\"\n",
    "    ),\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"musica\",\n",
    "            description=\"O usu√°rio quer tocar esta m√∫sica\",\n",
    "            examples=[],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"album\",\n",
    "            description=\"O usu√°rio deseja reproduzir este √°lbum\",\n",
    "            examples=[],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"artist\",\n",
    "            description=\"M√∫sica do artista fornecido\",\n",
    "            examples=[(\"M√∫sicas de paul simon\", \"paul simon\")],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"action\",\n",
    "            description=\"A√ß√£o para tomar um dos: `play`, `stop`, `next`, `previous`.\",\n",
    "            examples=[\n",
    "                (\"Por favor, pare a m√∫sica\", \"stop\"),\n",
    "                (\"Toque qualquer coisa\", \"play\"),\n",
    "                (\"Toque uma m√∫sica\", \"play\"),\n",
    "                (\"pr√≥xima m√∫sica\", \"next\"),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    many=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player': {'artist': ['paul simon', 'led zeppelin', 'the doors']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n",
    "chain.run(\"tocar m√∫sicas de Paul Simon e Led Zeppelin e The Doors\")['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic style schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from kor import create_extraction_chain, Object, Text, Number\n",
    "import pydantic\n",
    "from typing import List\n",
    "from kor import from_pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(enum.Enum):\n",
    "    play = \"play\"\n",
    "    stop = \"stop\"\n",
    "    previous = \"previous\"\n",
    "    next_ = \"next\"\n",
    "\n",
    "\n",
    "class MusicRequest(BaseModel):\n",
    "    song: Optional[List[str]] = Field(\n",
    "        description=\"The song(s) that the user would like to be played.\"\n",
    "    )\n",
    "    album: Optional[List[str]] = Field(\n",
    "        description=\"The album(s) that the user would like to be played.\"\n",
    "    )\n",
    "    artist: Optional[List[str]] = Field(\n",
    "        description=\"The artist(s) whose music the user would like to hear.\",\n",
    "        examples=[(\"Songs by paul simon\", \"paul simon\")],\n",
    "    )\n",
    "    action: Optional[Action] = Field(\n",
    "        description=\"The action that should be taken; one of `play`, `stop`, `next`, `previous`\",\n",
    "        examples=[\n",
    "            (\"Please stop the music\", \"stop\"),\n",
    "            (\"play something\", \"play\"),\n",
    "            (\"play a song\", \"play\"),\n",
    "            (\"next song\", \"next\"),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema, validator = from_pydantic(MusicRequest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_extraction_chain(\n",
    "    llm, schema, encoder_or_encoder_class=\"json\", validator=validator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
      "\n",
      "```TypeScript\n",
      "\n",
      "musicrequest: { // \n",
      " song: Array<string> // The song(s) that the user would like to be played.\n",
      " album: Array<string> // The album(s) that the user would like to be played.\n",
      " artist: Array<string> // The artist(s) whose music the user would like to hear.\n",
      " action: \"play\" | \"stop\" | \"previous\" | \"next\" // The action that should be taken; one of `play`, `stop`, `next`, `previous`\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "Please output the extracted information in JSON format. Do not output anything except for the extracted information. Do not add any clarifying information. Do not add any fields that are not in the schema. If the text contains attributes that do not appear in the schema, please ignore them. All output must be in JSON format and follow the schema specified above. Wrap the JSON in <json> tags.\n",
      "\n",
      "\n",
      "\n",
      "Input: Songs by paul simon\n",
      "Output: <json>{\"musicrequest\": {\"artist\": [\"paul simon\"]}}</json>\n",
      "Input: Please stop the music\n",
      "Output: <json>{\"musicrequest\": {\"action\": \"stop\"}}</json>\n",
      "Input: play something\n",
      "Output: <json>{\"musicrequest\": {\"action\": \"play\"}}</json>\n",
      "Input: play a song\n",
      "Output: <json>{\"musicrequest\": {\"action\": \"play\"}}</json>\n",
      "Input: next song\n",
      "Output: <json>{\"musicrequest\": {\"action\": \"next\"}}</json>\n",
      "Input: [user input]\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(chain.prompt.format_prompt(text=\"[user input]\").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"stop the music now\")[\"validated_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"i want to hear yellow submarine by the beatles\")[\n",
    "    \"validated_data\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
